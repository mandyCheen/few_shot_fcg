Pretrained model loaded from ./pretrained/x86_pretrained_GraphSAGE_3_layers_20250325_1459/epoch_83_0.971749856806638_best_backbone.pth
Device: cuda:0
Model: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.7405, Avg Train Acc: 0.4910 (Best)
Epoch 1/200: Avg Val Loss: 1.7349, Avg Val Acc: 0.5492 (Best)
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.6994, Avg Train Acc: 0.6597 (Best)
Epoch 2/200: Avg Val Loss: 1.7142, Avg Val Acc: 0.7221 (Best)
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.6781, Avg Train Acc: 0.8026 (Best)
Epoch 3/200: Avg Val Loss: 1.7080, Avg Val Acc: 0.7611 (Best)
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.6721, Avg Train Acc: 0.8287 (Best)
Epoch 4/200: Avg Val Loss: 1.6881, Avg Val Acc: 0.7924 (Best)
Patience: 0/20
Epoch 5/200: Avg Train Loss: 1.6681, Avg Train Acc: 0.8457 (Best)
Epoch 5/200: Avg Val Loss: 1.6880, Avg Val Acc: 0.8250 (Best)
Patience: 0/20
Epoch 6/200: Avg Train Loss: 1.6647, Avg Train Acc: 0.8553 (Best)
Epoch 6/200: Avg Val Loss: 1.6840, Avg Val Acc: 0.8107 (Best: 0.8250)
Patience: 1/20
Epoch 7/200: Avg Train Loss: 1.6617, Avg Train Acc: 0.8604 (Best)
Epoch 7/200: Avg Val Loss: 1.6850, Avg Val Acc: 0.8164 (Best: 0.8250)
Patience: 2/20
Epoch 8/200: Avg Train Loss: 1.6580, Avg Train Acc: 0.8692 (Best)
Epoch 8/200: Avg Val Loss: 1.6842, Avg Val Acc: 0.8091 (Best: 0.8250)
Patience: 3/20
Epoch 9/200: Avg Train Loss: 1.6596, Avg Train Acc: 0.8813 (Best)
Epoch 9/200: Avg Val Loss: 1.6840, Avg Val Acc: 0.8021 (Best: 0.8250)
Patience: 4/20
Epoch 10/200: Avg Train Loss: 1.6572, Avg Train Acc: 0.8756 (Best: 0.8813)
Epoch 10/200: Avg Val Loss: 1.6858, Avg Val Acc: 0.8131 (Best: 0.8250)
Patience: 5/20
Epoch 11/200: Avg Train Loss: 1.6632, Avg Train Acc: 0.8678 (Best: 0.8813)
Epoch 11/200: Avg Val Loss: 1.6857, Avg Val Acc: 0.8045 (Best: 0.8250)
Patience: 6/20
Epoch 12/200: Avg Train Loss: 1.6609, Avg Train Acc: 0.8713 (Best: 0.8813)
Epoch 12/200: Avg Val Loss: 1.6805, Avg Val Acc: 0.7996 (Best: 0.8250)
Patience: 7/20
Epoch 13/200: Avg Train Loss: 1.6557, Avg Train Acc: 0.8804 (Best: 0.8813)
Epoch 13/200: Avg Val Loss: 1.6849, Avg Val Acc: 0.8137 (Best: 0.8250)
Patience: 8/20
Epoch 14/200: Avg Train Loss: 1.6565, Avg Train Acc: 0.8793 (Best: 0.8813)
Epoch 14/200: Avg Val Loss: 1.6846, Avg Val Acc: 0.8040 (Best: 0.8250)
Patience: 9/20
Epoch 15/200: Avg Train Loss: 1.6540, Avg Train Acc: 0.8852 (Best)
Epoch 15/200: Avg Val Loss: 1.6864, Avg Val Acc: 0.8167 (Best: 0.8250)
Patience: 10/20
Epoch 16/200: Avg Train Loss: 1.6543, Avg Train Acc: 0.8786 (Best: 0.8852)
Epoch 16/200: Avg Val Loss: 1.6906, Avg Val Acc: 0.8029 (Best: 0.8250)
Patience: 11/20
Epoch 17/200: Avg Train Loss: 1.6517, Avg Train Acc: 0.8901 (Best)
Epoch 17/200: Avg Val Loss: 1.6845, Avg Val Acc: 0.8095 (Best: 0.8250)
Patience: 12/20
Epoch 18/200: Avg Train Loss: 1.6522, Avg Train Acc: 0.8904 (Best)
Epoch 18/200: Avg Val Loss: 1.6903, Avg Val Acc: 0.8100 (Best: 0.8250)
Patience: 13/20
Epoch 19/200: Avg Train Loss: 1.6534, Avg Train Acc: 0.8863 (Best: 0.8904)
Epoch 19/200: Avg Val Loss: 1.6900, Avg Val Acc: 0.8184 (Best: 0.8250)
Patience: 14/20
Epoch 20/200: Avg Train Loss: 1.6473, Avg Train Acc: 0.8905 (Best)
Epoch 20/200: Avg Val Loss: 1.6968, Avg Val Acc: 0.8142 (Best: 0.8250)
Patience: 15/20
Epoch 21/200: Avg Train Loss: 1.6512, Avg Train Acc: 0.8857 (Best: 0.8905)
Epoch 21/200: Avg Val Loss: 1.6975, Avg Val Acc: 0.8175 (Best: 0.8250)
Patience: 16/20
Epoch 22/200: Avg Train Loss: 1.6509, Avg Train Acc: 0.8866 (Best: 0.8905)
Epoch 22/200: Avg Val Loss: 1.6909, Avg Val Acc: 0.8167 (Best: 0.8250)
Patience: 17/20
Epoch 23/200: Avg Train Loss: 1.6483, Avg Train Acc: 0.8903 (Best: 0.8905)
Epoch 23/200: Avg Val Loss: 1.6926, Avg Val Acc: 0.8207 (Best: 0.8250)
Patience: 18/20
Epoch 24/200: Avg Train Loss: 1.6494, Avg Train Acc: 0.9002 (Best)
Epoch 24/200: Avg Val Loss: 1.6990, Avg Val Acc: 0.8039 (Best: 0.8250)
Patience: 19/20
Epoch 25/200: Avg Train Loss: 1.6500, Avg Train Acc: 0.8919 (Best: 0.9002)
Epoch 25/200: Avg Val Loss: 1.6905, Avg Val Acc: 0.8239 (Best: 0.8250)
Early stopping in epoch 25
Finish training
