Device: cuda:0
Model: LabelPropagation(
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 64, aggr=mean)
      )
      (norms): ModuleList(
        (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
  )
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
Loss function: LabelPropagation(
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 64, aggr=mean)
      )
      (norms): ModuleList(
        (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=1, bias=True)
    )
  )
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/500: Avg Train Loss: 0.7770, Avg Train Acc: 0.7673 (Best)
Epoch 1/500: Avg Val Loss: 0.9067, Avg Val Acc: 0.7345 (Best)
Patience: 0/20
Epoch 2/500: Avg Train Loss: 0.7188, Avg Train Acc: 0.7710 (Best)
Epoch 2/500: Avg Val Loss: 0.8556, Avg Val Acc: 0.7306 (Best: 0.7345)
Patience: 1/20
Epoch 3/500: Avg Train Loss: 0.6749, Avg Train Acc: 0.7814 (Best)
Epoch 3/500: Avg Val Loss: 0.7698, Avg Val Acc: 0.7659 (Best)
Patience: 0/20
Epoch 4/500: Avg Train Loss: 0.6692, Avg Train Acc: 0.7893 (Best)
Epoch 4/500: Avg Val Loss: 0.8326, Avg Val Acc: 0.7438 (Best: 0.7659)
Patience: 1/20
Epoch 5/500: Avg Train Loss: 0.6529, Avg Train Acc: 0.7944 (Best)
Epoch 5/500: Avg Val Loss: 0.8354, Avg Val Acc: 0.7539 (Best: 0.7659)
Patience: 2/20
Epoch 6/500: Avg Train Loss: 0.6362, Avg Train Acc: 0.7967 (Best)
Epoch 6/500: Avg Val Loss: 0.8588, Avg Val Acc: 0.7500 (Best: 0.7659)
Patience: 3/20
Epoch 7/500: Avg Train Loss: 0.6131, Avg Train Acc: 0.8041 (Best)
Epoch 7/500: Avg Val Loss: 0.8550, Avg Val Acc: 0.7549 (Best: 0.7659)
Patience: 4/20
Epoch 8/500: Avg Train Loss: 0.6015, Avg Train Acc: 0.8051 (Best)
Epoch 8/500: Avg Val Loss: 0.8354, Avg Val Acc: 0.7568 (Best: 0.7659)
Patience: 5/20
Epoch 9/500: Avg Train Loss: 0.5994, Avg Train Acc: 0.8067 (Best)
Epoch 9/500: Avg Val Loss: 0.8484, Avg Val Acc: 0.7507 (Best: 0.7659)
Patience: 6/20
