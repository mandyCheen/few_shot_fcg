Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.1480, Avg Train Acc: 0.8223 (Best)
Epoch 1/200: Avg Val Loss: 1.1250, Avg Val Acc: 0.8815 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.1258, Avg Train Acc: 0.8742 (Best)
Epoch 2/200: Avg Val Loss: 1.1274, Avg Val Acc: 0.8757 (Best: 0.8815)
Current learning rate: [0.001]
Patience: 1/20
Epoch 3/200: Avg Train Loss: 1.1181, Avg Train Acc: 0.8929 (Best)
Epoch 3/200: Avg Val Loss: 1.1237, Avg Val Acc: 0.9007 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.1030, Avg Train Acc: 0.9114 (Best)
Epoch 4/200: Avg Val Loss: 1.1240, Avg Val Acc: 0.8908 (Best: 0.9007)
Current learning rate: [0.001]
Patience: 1/20
Epoch 5/200: Avg Train Loss: 1.1018, Avg Train Acc: 0.9028 (Best: 0.9114)
Epoch 5/200: Avg Val Loss: 1.1183, Avg Val Acc: 0.9036 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 6/200: Avg Train Loss: 1.1006, Avg Train Acc: 0.9163 (Best)
Epoch 6/200: Avg Val Loss: 1.1141, Avg Val Acc: 0.9063 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 7/200: Avg Train Loss: 1.1015, Avg Train Acc: 0.8998 (Best: 0.9163)
Epoch 7/200: Avg Val Loss: 1.1241, Avg Val Acc: 0.9088 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 8/200: Avg Train Loss: 1.0981, Avg Train Acc: 0.9166 (Best)
Epoch 8/200: Avg Val Loss: 1.1161, Avg Val Acc: 0.9117 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 9/200: Avg Train Loss: 1.1010, Avg Train Acc: 0.9074 (Best: 0.9166)
Epoch 9/200: Avg Val Loss: 1.1389, Avg Val Acc: 0.9105 (Best: 0.9117)
Current learning rate: [0.001]
Patience: 1/20
Epoch 10/200: Avg Train Loss: 1.0987, Avg Train Acc: 0.9086 (Best: 0.9166)
Epoch 10/200: Avg Val Loss: 1.1209, Avg Val Acc: 0.9131 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 11/200: Avg Train Loss: 1.0944, Avg Train Acc: 0.9147 (Best: 0.9166)
Epoch 11/200: Avg Val Loss: 1.1064, Avg Val Acc: 0.9047 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 1/20
Epoch 12/200: Avg Train Loss: 1.0954, Avg Train Acc: 0.9071 (Best: 0.9166)
Epoch 12/200: Avg Val Loss: 1.1135, Avg Val Acc: 0.9080 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 2/20
Epoch 13/200: Avg Train Loss: 1.0975, Avg Train Acc: 0.9152 (Best: 0.9166)
Epoch 13/200: Avg Val Loss: 1.1092, Avg Val Acc: 0.9045 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 3/20
Epoch 14/200: Avg Train Loss: 1.0958, Avg Train Acc: 0.9096 (Best: 0.9166)
Epoch 14/200: Avg Val Loss: 1.1173, Avg Val Acc: 0.9042 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 4/20
Epoch 15/200: Avg Train Loss: 1.0943, Avg Train Acc: 0.9191 (Best)
Epoch 15/200: Avg Val Loss: 1.1346, Avg Val Acc: 0.9056 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 5/20
Epoch 16/200: Avg Train Loss: 1.0926, Avg Train Acc: 0.9135 (Best: 0.9191)
Epoch 16/200: Avg Val Loss: 1.1205, Avg Val Acc: 0.9021 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 6/20
Epoch 17/200: Avg Train Loss: 1.0916, Avg Train Acc: 0.9158 (Best: 0.9191)
Epoch 17/200: Avg Val Loss: 1.1138, Avg Val Acc: 0.9126 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 7/20
Epoch 18/200: Avg Train Loss: 1.0928, Avg Train Acc: 0.9135 (Best: 0.9191)
Epoch 18/200: Avg Val Loss: 1.1389, Avg Val Acc: 0.9001 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 8/20
Epoch 19/200: Avg Train Loss: 1.0950, Avg Train Acc: 0.9098 (Best: 0.9191)
Epoch 19/200: Avg Val Loss: 1.1259, Avg Val Acc: 0.9006 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 9/20
Epoch 20/200: Avg Train Loss: 1.0938, Avg Train Acc: 0.9160 (Best: 0.9191)
Epoch 20/200: Avg Val Loss: 1.1168, Avg Val Acc: 0.9007 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 10/20
Epoch 21/200: Avg Train Loss: 1.0912, Avg Train Acc: 0.9173 (Best: 0.9191)
Epoch 21/200: Avg Val Loss: 1.1098, Avg Val Acc: 0.8979 (Best: 0.9131)
Current learning rate: [0.001]
Patience: 11/20
Epoch 22/200: Avg Train Loss: 1.0943, Avg Train Acc: 0.9109 (Best: 0.9191)
Epoch 22/200: Avg Val Loss: 1.1100, Avg Val Acc: 0.9002 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 23/200: Avg Train Loss: 1.0914, Avg Train Acc: 0.9119 (Best: 0.9191)
Epoch 23/200: Avg Val Loss: 1.1137, Avg Val Acc: 0.8920 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 24/200: Avg Train Loss: 1.0838, Avg Train Acc: 0.9209 (Best)
Epoch 24/200: Avg Val Loss: 1.1324, Avg Val Acc: 0.8981 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 14/20
Epoch 25/200: Avg Train Loss: 1.0793, Avg Train Acc: 0.9252 (Best)
Epoch 25/200: Avg Val Loss: 1.1241, Avg Val Acc: 0.8929 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 15/20
Epoch 26/200: Avg Train Loss: 1.0853, Avg Train Acc: 0.9232 (Best: 0.9252)
Epoch 26/200: Avg Val Loss: 1.1013, Avg Val Acc: 0.9044 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 16/20
Epoch 27/200: Avg Train Loss: 1.0878, Avg Train Acc: 0.9140 (Best: 0.9252)
Epoch 27/200: Avg Val Loss: 1.1097, Avg Val Acc: 0.8928 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 17/20
Epoch 28/200: Avg Train Loss: 1.0834, Avg Train Acc: 0.9200 (Best: 0.9252)
Epoch 28/200: Avg Val Loss: 1.1236, Avg Val Acc: 0.8900 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 18/20
Epoch 29/200: Avg Train Loss: 1.0882, Avg Train Acc: 0.9124 (Best: 0.9252)
Epoch 29/200: Avg Val Loss: 1.1199, Avg Val Acc: 0.8918 (Best: 0.9131)
Current learning rate: [0.0005]
Patience: 19/20
Epoch 30/200: Avg Train Loss: 1.0836, Avg Train Acc: 0.9137 (Best: 0.9252)
Epoch 30/200: Avg Val Loss: 1.1199, Avg Val Acc: 0.8986 (Best: 0.9131)
Current learning rate: [0.0005]
Early stopping in epoch 30
Finish training
