Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.1069, Avg Train Acc: 0.8599 (Best)
Epoch 1/200: Avg Val Loss: 1.2091, Avg Val Acc: 0.7792 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.0939, Avg Train Acc: 0.8840 (Best)
Epoch 2/200: Avg Val Loss: 1.1418, Avg Val Acc: 0.8285 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.0936, Avg Train Acc: 0.8956 (Best)
Epoch 3/200: Avg Val Loss: 1.1072, Avg Val Acc: 0.8320 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.0833, Avg Train Acc: 0.9164 (Best)
Epoch 4/200: Avg Val Loss: 1.1256, Avg Val Acc: 0.8252 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 1/20
Epoch 5/200: Avg Train Loss: 1.0810, Avg Train Acc: 0.9160 (Best: 0.9164)
Epoch 5/200: Avg Val Loss: 1.1245, Avg Val Acc: 0.8167 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 2/20
Epoch 6/200: Avg Train Loss: 1.0876, Avg Train Acc: 0.9041 (Best: 0.9164)
Epoch 6/200: Avg Val Loss: 1.1230, Avg Val Acc: 0.8276 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 3/20
Epoch 7/200: Avg Train Loss: 1.0871, Avg Train Acc: 0.9000 (Best: 0.9164)
Epoch 7/200: Avg Val Loss: 1.1451, Avg Val Acc: 0.8059 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 4/20
Epoch 8/200: Avg Train Loss: 1.0796, Avg Train Acc: 0.9151 (Best: 0.9164)
Epoch 8/200: Avg Val Loss: 1.1329, Avg Val Acc: 0.8319 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 5/20
Epoch 9/200: Avg Train Loss: 1.0807, Avg Train Acc: 0.9143 (Best: 0.9164)
Epoch 9/200: Avg Val Loss: 1.1644, Avg Val Acc: 0.8145 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 6/20
Epoch 10/200: Avg Train Loss: 1.0839, Avg Train Acc: 0.9083 (Best: 0.9164)
Epoch 10/200: Avg Val Loss: 1.1282, Avg Val Acc: 0.8259 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 7/20
Epoch 11/200: Avg Train Loss: 1.0810, Avg Train Acc: 0.9081 (Best: 0.9164)
Epoch 11/200: Avg Val Loss: 1.1298, Avg Val Acc: 0.8227 (Best: 0.8320)
Current learning rate: [0.001]
Patience: 8/20
Epoch 12/200: Avg Train Loss: 1.0784, Avg Train Acc: 0.9172 (Best)
Epoch 12/200: Avg Val Loss: 1.1287, Avg Val Acc: 0.8387 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 13/200: Avg Train Loss: 1.0800, Avg Train Acc: 0.9071 (Best: 0.9172)
Epoch 13/200: Avg Val Loss: 1.1080, Avg Val Acc: 0.8335 (Best: 0.8387)
Current learning rate: [0.001]
Patience: 1/20
Epoch 14/200: Avg Train Loss: 1.0755, Avg Train Acc: 0.9219 (Best)
Epoch 14/200: Avg Val Loss: 1.1341, Avg Val Acc: 0.8271 (Best: 0.8387)
Current learning rate: [0.0005]
Patience: 2/20
Epoch 15/200: Avg Train Loss: 1.0745, Avg Train Acc: 0.9172 (Best: 0.9219)
Epoch 15/200: Avg Val Loss: 1.1212, Avg Val Acc: 0.8669 (Best)
Current learning rate: [0.0005]
Patience: 0/20
Epoch 16/200: Avg Train Loss: 1.0783, Avg Train Acc: 0.9049 (Best: 0.9219)
Epoch 16/200: Avg Val Loss: 1.1271, Avg Val Acc: 0.8405 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 1/20
Epoch 17/200: Avg Train Loss: 1.0735, Avg Train Acc: 0.9264 (Best)
Epoch 17/200: Avg Val Loss: 1.1464, Avg Val Acc: 0.8203 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 2/20
Epoch 18/200: Avg Train Loss: 1.0763, Avg Train Acc: 0.9123 (Best: 0.9264)
Epoch 18/200: Avg Val Loss: 1.1414, Avg Val Acc: 0.8273 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 3/20
Epoch 19/200: Avg Train Loss: 1.0783, Avg Train Acc: 0.9089 (Best: 0.9264)
Epoch 19/200: Avg Val Loss: 1.1057, Avg Val Acc: 0.8463 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 4/20
Epoch 20/200: Avg Train Loss: 1.0801, Avg Train Acc: 0.9111 (Best: 0.9264)
Epoch 20/200: Avg Val Loss: 1.1353, Avg Val Acc: 0.8333 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 5/20
Epoch 21/200: Avg Train Loss: 1.0765, Avg Train Acc: 0.9225 (Best: 0.9264)
Epoch 21/200: Avg Val Loss: 1.1286, Avg Val Acc: 0.8313 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 6/20
Epoch 22/200: Avg Train Loss: 1.0750, Avg Train Acc: 0.9124 (Best: 0.9264)
Epoch 22/200: Avg Val Loss: 1.1610, Avg Val Acc: 0.8127 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 7/20
Epoch 23/200: Avg Train Loss: 1.0744, Avg Train Acc: 0.9195 (Best: 0.9264)
Epoch 23/200: Avg Val Loss: 1.1369, Avg Val Acc: 0.8251 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 8/20
Epoch 24/200: Avg Train Loss: 1.0733, Avg Train Acc: 0.9140 (Best: 0.9264)
Epoch 24/200: Avg Val Loss: 1.1362, Avg Val Acc: 0.8405 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 9/20
Epoch 25/200: Avg Train Loss: 1.0747, Avg Train Acc: 0.9193 (Best: 0.9264)
Epoch 25/200: Avg Val Loss: 1.1342, Avg Val Acc: 0.8376 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 10/20
Epoch 26/200: Avg Train Loss: 1.0733, Avg Train Acc: 0.9256 (Best: 0.9264)
Epoch 26/200: Avg Val Loss: 1.1628, Avg Val Acc: 0.8177 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 11/20
Epoch 27/200: Avg Train Loss: 1.0751, Avg Train Acc: 0.9145 (Best: 0.9264)
Epoch 27/200: Avg Val Loss: 1.1336, Avg Val Acc: 0.8372 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 28/200: Avg Train Loss: 1.0691, Avg Train Acc: 0.9273 (Best)
Epoch 28/200: Avg Val Loss: 1.1331, Avg Val Acc: 0.8311 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 29/200: Avg Train Loss: 1.0715, Avg Train Acc: 0.9297 (Best)
Epoch 29/200: Avg Val Loss: 1.2075, Avg Val Acc: 0.7535 (Best: 0.8669)
Current learning rate: [0.0005]
Patience: 14/20
Epoch 30/200: Avg Train Loss: 1.0721, Avg Train Acc: 0.9188 (Best: 0.9297)
Epoch 30/200: Avg Val Loss: 1.1628, Avg Val Acc: 0.8128 (Best: 0.8669)
Current learning rate: [0.00025]
Patience: 15/20
Epoch 31/200: Avg Train Loss: 1.0678, Avg Train Acc: 0.9395 (Best)
Epoch 31/200: Avg Val Loss: 1.1656, Avg Val Acc: 0.8065 (Best: 0.8669)
Current learning rate: [0.00025]
Patience: 16/20
Epoch 32/200: Avg Train Loss: 1.0752, Avg Train Acc: 0.9113 (Best: 0.9395)
Epoch 32/200: Avg Val Loss: 1.1253, Avg Val Acc: 0.8568 (Best: 0.8669)
Current learning rate: [0.00025]
Patience: 17/20
Epoch 33/200: Avg Train Loss: 1.0719, Avg Train Acc: 0.9205 (Best: 0.9395)
Epoch 33/200: Avg Val Loss: 1.1513, Avg Val Acc: 0.8268 (Best: 0.8669)
Current learning rate: [0.00025]
Patience: 18/20
Epoch 34/200: Avg Train Loss: 1.0741, Avg Train Acc: 0.9203 (Best: 0.9395)
Epoch 34/200: Avg Val Loss: 1.1566, Avg Val Acc: 0.8203 (Best: 0.8669)
Current learning rate: [0.00025]
Patience: 19/20
Epoch 35/200: Avg Train Loss: 1.0710, Avg Train Acc: 0.9329 (Best: 0.9395)
Epoch 35/200: Avg Val Loss: 1.1773, Avg Val Acc: 0.8165 (Best: 0.8669)
Current learning rate: [0.00025]
Early stopping in epoch 35
Finish training
