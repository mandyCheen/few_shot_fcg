Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.6903, Avg Train Acc: 0.7860 (Best)
Epoch 1/200: Avg Val Loss: 1.7034, Avg Val Acc: 0.7363 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.6773, Avg Train Acc: 0.8495 (Best)
Epoch 2/200: Avg Val Loss: 1.7064, Avg Val Acc: 0.7705 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.6704, Avg Train Acc: 0.8589 (Best)
Epoch 3/200: Avg Val Loss: 1.7036, Avg Val Acc: 0.8066 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.6644, Avg Train Acc: 0.8689 (Best)
Epoch 4/200: Avg Val Loss: 1.7073, Avg Val Acc: 0.8035 (Best: 0.8066)
Current learning rate: [0.001]
Patience: 1/20
Epoch 5/200: Avg Train Loss: 1.6688, Avg Train Acc: 0.8659 (Best: 0.8689)
Epoch 5/200: Avg Val Loss: 1.7135, Avg Val Acc: 0.7971 (Best: 0.8066)
Current learning rate: [0.001]
Patience: 2/20
Epoch 6/200: Avg Train Loss: 1.6693, Avg Train Acc: 0.8471 (Best: 0.8689)
Epoch 6/200: Avg Val Loss: 1.7230, Avg Val Acc: 0.8102 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 7/200: Avg Train Loss: 1.6680, Avg Train Acc: 0.8581 (Best: 0.8689)
Epoch 7/200: Avg Val Loss: 1.7209, Avg Val Acc: 0.7871 (Best: 0.8102)
Current learning rate: [0.001]
Patience: 1/20
Epoch 8/200: Avg Train Loss: 1.6637, Avg Train Acc: 0.8711 (Best)
Epoch 8/200: Avg Val Loss: 1.7082, Avg Val Acc: 0.8141 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 9/200: Avg Train Loss: 1.6645, Avg Train Acc: 0.8664 (Best: 0.8711)
Epoch 9/200: Avg Val Loss: 1.7357, Avg Val Acc: 0.7867 (Best: 0.8141)
Current learning rate: [0.001]
Patience: 1/20
Epoch 10/200: Avg Train Loss: 1.6587, Avg Train Acc: 0.8791 (Best)
Epoch 10/200: Avg Val Loss: 1.7228, Avg Val Acc: 0.7893 (Best: 0.8141)
Current learning rate: [0.001]
Patience: 2/20
Epoch 11/200: Avg Train Loss: 1.6617, Avg Train Acc: 0.8724 (Best: 0.8791)
Epoch 11/200: Avg Val Loss: 1.7309, Avg Val Acc: 0.7863 (Best: 0.8141)
Current learning rate: [0.001]
Patience: 3/20
Epoch 12/200: Avg Train Loss: 1.6614, Avg Train Acc: 0.8746 (Best: 0.8791)
Epoch 12/200: Avg Val Loss: 1.7429, Avg Val Acc: 0.7723 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 4/20
Epoch 13/200: Avg Train Loss: 1.6584, Avg Train Acc: 0.8776 (Best: 0.8791)
Epoch 13/200: Avg Val Loss: 1.7348, Avg Val Acc: 0.7785 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 5/20
Epoch 14/200: Avg Train Loss: 1.6584, Avg Train Acc: 0.8765 (Best: 0.8791)
Epoch 14/200: Avg Val Loss: 1.7260, Avg Val Acc: 0.7864 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 6/20
Epoch 15/200: Avg Train Loss: 1.6584, Avg Train Acc: 0.8790 (Best: 0.8791)
Epoch 15/200: Avg Val Loss: 1.7213, Avg Val Acc: 0.7785 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 7/20
Epoch 16/200: Avg Train Loss: 1.6553, Avg Train Acc: 0.8791 (Best: 0.8791)
Epoch 16/200: Avg Val Loss: 1.7119, Avg Val Acc: 0.7779 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 8/20
Epoch 17/200: Avg Train Loss: 1.6546, Avg Train Acc: 0.8795 (Best)
Epoch 17/200: Avg Val Loss: 1.7321, Avg Val Acc: 0.7895 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 9/20
Epoch 18/200: Avg Train Loss: 1.6556, Avg Train Acc: 0.8880 (Best)
Epoch 18/200: Avg Val Loss: 1.7212, Avg Val Acc: 0.7954 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 10/20
Epoch 19/200: Avg Train Loss: 1.6567, Avg Train Acc: 0.8826 (Best: 0.8880)
Epoch 19/200: Avg Val Loss: 1.7265, Avg Val Acc: 0.7859 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 11/20
Epoch 20/200: Avg Train Loss: 1.6538, Avg Train Acc: 0.8924 (Best)
Epoch 20/200: Avg Val Loss: 1.7260, Avg Val Acc: 0.7757 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 21/200: Avg Train Loss: 1.6550, Avg Train Acc: 0.8891 (Best: 0.8924)
Epoch 21/200: Avg Val Loss: 1.7161, Avg Val Acc: 0.8005 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 22/200: Avg Train Loss: 1.6581, Avg Train Acc: 0.8863 (Best: 0.8924)
Epoch 22/200: Avg Val Loss: 1.7273, Avg Val Acc: 0.7993 (Best: 0.8141)
Current learning rate: [0.0005]
Patience: 14/20
Epoch 23/200: Avg Train Loss: 1.6536, Avg Train Acc: 0.8862 (Best: 0.8924)
Epoch 23/200: Avg Val Loss: 1.7543, Avg Val Acc: 0.7569 (Best: 0.8141)
Current learning rate: [0.00025]
Patience: 15/20
Epoch 24/200: Avg Train Loss: 1.6515, Avg Train Acc: 0.8960 (Best)
Epoch 24/200: Avg Val Loss: 1.7193, Avg Val Acc: 0.7911 (Best: 0.8141)
Current learning rate: [0.00025]
Patience: 16/20
Epoch 25/200: Avg Train Loss: 1.6529, Avg Train Acc: 0.8920 (Best: 0.8960)
Epoch 25/200: Avg Val Loss: 1.7188, Avg Val Acc: 0.7913 (Best: 0.8141)
Current learning rate: [0.00025]
Patience: 17/20
Epoch 26/200: Avg Train Loss: 1.6518, Avg Train Acc: 0.8843 (Best: 0.8960)
Epoch 26/200: Avg Val Loss: 1.7227, Avg Val Acc: 0.7833 (Best: 0.8141)
Current learning rate: [0.00025]
Patience: 18/20
Epoch 27/200: Avg Train Loss: 1.6547, Avg Train Acc: 0.8843 (Best: 0.8960)
Epoch 27/200: Avg Val Loss: 1.7617, Avg Val Acc: 0.7488 (Best: 0.8141)
Current learning rate: [0.00025]
Patience: 19/20
Epoch 28/200: Avg Train Loss: 1.6535, Avg Train Acc: 0.8879 (Best: 0.8960)
Epoch 28/200: Avg Val Loss: 1.7105, Avg Val Acc: 0.8025 (Best: 0.8141)
Current learning rate: [0.00025]
Early stopping in epoch 28
Finish training
