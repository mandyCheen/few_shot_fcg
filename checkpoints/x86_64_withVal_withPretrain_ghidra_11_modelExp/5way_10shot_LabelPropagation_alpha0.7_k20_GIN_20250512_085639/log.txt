Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 0.6943, Avg Train Acc: 0.8964 (Best)
Epoch 1/200: Avg Val Loss: 0.7108, Avg Val Acc: 0.8362 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 0.6801, Avg Train Acc: 0.9180 (Best)
Epoch 2/200: Avg Val Loss: 0.6971, Avg Val Acc: 0.8744 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 0.6676, Avg Train Acc: 0.9290 (Best)
Epoch 3/200: Avg Val Loss: 0.7630, Avg Val Acc: 0.8388 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 1/20
Epoch 4/200: Avg Train Loss: 0.6707, Avg Train Acc: 0.9286 (Best: 0.9290)
Epoch 4/200: Avg Val Loss: 0.7568, Avg Val Acc: 0.8542 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 2/20
Epoch 5/200: Avg Train Loss: 0.6689, Avg Train Acc: 0.9306 (Best)
Epoch 5/200: Avg Val Loss: 0.7509, Avg Val Acc: 0.8474 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 3/20
Epoch 6/200: Avg Train Loss: 0.6656, Avg Train Acc: 0.9334 (Best)
Epoch 6/200: Avg Val Loss: 0.7185, Avg Val Acc: 0.8638 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 4/20
Epoch 7/200: Avg Train Loss: 0.6645, Avg Train Acc: 0.9356 (Best)
Epoch 7/200: Avg Val Loss: 0.7278, Avg Val Acc: 0.8606 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 5/20
Epoch 8/200: Avg Train Loss: 0.6715, Avg Train Acc: 0.9188 (Best: 0.9356)
Epoch 8/200: Avg Val Loss: 0.7396, Avg Val Acc: 0.8610 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 6/20
Epoch 9/200: Avg Train Loss: 0.6665, Avg Train Acc: 0.9304 (Best: 0.9356)
Epoch 9/200: Avg Val Loss: 0.7096, Avg Val Acc: 0.8742 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 7/20
Epoch 10/200: Avg Train Loss: 0.6680, Avg Train Acc: 0.9296 (Best: 0.9356)
Epoch 10/200: Avg Val Loss: 0.7340, Avg Val Acc: 0.8600 (Best: 0.8744)
Current learning rate: [0.001]
Patience: 8/20
Epoch 11/200: Avg Train Loss: 0.6621, Avg Train Acc: 0.9360 (Best)
Epoch 11/200: Avg Val Loss: 0.6957, Avg Val Acc: 0.8898 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 12/200: Avg Train Loss: 0.6644, Avg Train Acc: 0.9400 (Best)
Epoch 12/200: Avg Val Loss: 0.7190, Avg Val Acc: 0.8538 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 1/20
Epoch 13/200: Avg Train Loss: 0.6635, Avg Train Acc: 0.9258 (Best: 0.9400)
Epoch 13/200: Avg Val Loss: 0.7300, Avg Val Acc: 0.8502 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 2/20
Epoch 14/200: Avg Train Loss: 0.6596, Avg Train Acc: 0.9368 (Best: 0.9400)
Epoch 14/200: Avg Val Loss: 0.7734, Avg Val Acc: 0.8326 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 3/20
Epoch 15/200: Avg Train Loss: 0.6695, Avg Train Acc: 0.9272 (Best: 0.9400)
Epoch 15/200: Avg Val Loss: 0.7121, Avg Val Acc: 0.8576 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 4/20
Epoch 16/200: Avg Train Loss: 0.6611, Avg Train Acc: 0.9318 (Best: 0.9400)
Epoch 16/200: Avg Val Loss: 0.7359, Avg Val Acc: 0.8540 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 5/20
Epoch 17/200: Avg Train Loss: 0.6531, Avg Train Acc: 0.9440 (Best)
Epoch 17/200: Avg Val Loss: 0.7158, Avg Val Acc: 0.8618 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 6/20
Epoch 18/200: Avg Train Loss: 0.6535, Avg Train Acc: 0.9364 (Best: 0.9440)
Epoch 18/200: Avg Val Loss: 0.7391, Avg Val Acc: 0.8494 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 7/20
Epoch 19/200: Avg Train Loss: 0.6565, Avg Train Acc: 0.9358 (Best: 0.9440)
Epoch 19/200: Avg Val Loss: 0.7357, Avg Val Acc: 0.8418 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 8/20
Epoch 20/200: Avg Train Loss: 0.6564, Avg Train Acc: 0.9358 (Best: 0.9440)
Epoch 20/200: Avg Val Loss: 0.7581, Avg Val Acc: 0.8338 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 9/20
Epoch 21/200: Avg Train Loss: 0.6591, Avg Train Acc: 0.9354 (Best: 0.9440)
Epoch 21/200: Avg Val Loss: 0.7406, Avg Val Acc: 0.8444 (Best: 0.8898)
Current learning rate: [0.001]
Patience: 10/20
Epoch 22/200: Avg Train Loss: 0.6635, Avg Train Acc: 0.9302 (Best: 0.9440)
Epoch 22/200: Avg Val Loss: 0.7715, Avg Val Acc: 0.8288 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 11/20
Epoch 23/200: Avg Train Loss: 0.6583, Avg Train Acc: 0.9402 (Best: 0.9440)
Epoch 23/200: Avg Val Loss: 0.7779, Avg Val Acc: 0.8350 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 24/200: Avg Train Loss: 0.6528, Avg Train Acc: 0.9454 (Best)
Epoch 24/200: Avg Val Loss: 0.7086, Avg Val Acc: 0.8688 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 25/200: Avg Train Loss: 0.6542, Avg Train Acc: 0.9464 (Best)
Epoch 25/200: Avg Val Loss: 0.7477, Avg Val Acc: 0.8440 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 14/20
Epoch 26/200: Avg Train Loss: 0.6520, Avg Train Acc: 0.9430 (Best: 0.9464)
Epoch 26/200: Avg Val Loss: 0.7355, Avg Val Acc: 0.8468 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 15/20
Epoch 27/200: Avg Train Loss: 0.6593, Avg Train Acc: 0.9282 (Best: 0.9464)
Epoch 27/200: Avg Val Loss: 0.7795, Avg Val Acc: 0.8296 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 16/20
Epoch 28/200: Avg Train Loss: 0.6605, Avg Train Acc: 0.9328 (Best: 0.9464)
Epoch 28/200: Avg Val Loss: 0.7515, Avg Val Acc: 0.8504 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 17/20
Epoch 29/200: Avg Train Loss: 0.6508, Avg Train Acc: 0.9422 (Best: 0.9464)
Epoch 29/200: Avg Val Loss: 0.7294, Avg Val Acc: 0.8496 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 18/20
Epoch 30/200: Avg Train Loss: 0.6472, Avg Train Acc: 0.9514 (Best)
Epoch 30/200: Avg Val Loss: 0.7927, Avg Val Acc: 0.8054 (Best: 0.8898)
Current learning rate: [0.0005]
Patience: 19/20
Epoch 31/200: Avg Train Loss: 0.6537, Avg Train Acc: 0.9388 (Best: 0.9514)
Epoch 31/200: Avg Val Loss: 0.7366, Avg Val Acc: 0.8610 (Best: 0.8898)
Current learning rate: [0.0005]
Early stopping in epoch 31
Finish training
