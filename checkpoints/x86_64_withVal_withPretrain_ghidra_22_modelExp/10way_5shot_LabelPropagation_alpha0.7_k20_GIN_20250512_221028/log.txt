Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.7029, Avg Train Acc: 0.7103 (Best)
Epoch 1/200: Avg Val Loss: 1.7245, Avg Val Acc: 0.8703 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.6764, Avg Train Acc: 0.8304 (Best)
Epoch 2/200: Avg Val Loss: 1.6959, Avg Val Acc: 0.8313 (Best: 0.8703)
Current learning rate: [0.001]
Patience: 1/20
Epoch 3/200: Avg Train Loss: 1.6723, Avg Train Acc: 0.8547 (Best)
Epoch 3/200: Avg Val Loss: 1.6790, Avg Val Acc: 0.8793 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.6666, Avg Train Acc: 0.8519 (Best: 0.8547)
Epoch 4/200: Avg Val Loss: 1.6655, Avg Val Acc: 0.8575 (Best: 0.8793)
Current learning rate: [0.001]
Patience: 1/20
Epoch 5/200: Avg Train Loss: 1.6663, Avg Train Acc: 0.8636 (Best)
Epoch 5/200: Avg Val Loss: 1.7021, Avg Val Acc: 0.8866 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 6/200: Avg Train Loss: 1.6609, Avg Train Acc: 0.8790 (Best)
Epoch 6/200: Avg Val Loss: 1.7279, Avg Val Acc: 0.8525 (Best: 0.8866)
Current learning rate: [0.001]
Patience: 1/20
Epoch 7/200: Avg Train Loss: 1.6621, Avg Train Acc: 0.8655 (Best: 0.8790)
Epoch 7/200: Avg Val Loss: 1.7302, Avg Val Acc: 0.8399 (Best: 0.8866)
Current learning rate: [0.001]
Patience: 2/20
Epoch 8/200: Avg Train Loss: 1.6610, Avg Train Acc: 0.8783 (Best: 0.8790)
Epoch 8/200: Avg Val Loss: 1.7217, Avg Val Acc: 0.8752 (Best: 0.8866)
Current learning rate: [0.001]
Patience: 3/20
Epoch 9/200: Avg Train Loss: 1.6669, Avg Train Acc: 0.8593 (Best: 0.8790)
Epoch 9/200: Avg Val Loss: 1.7171, Avg Val Acc: 0.8684 (Best: 0.8866)
Current learning rate: [0.001]
Patience: 4/20
Epoch 10/200: Avg Train Loss: 1.6626, Avg Train Acc: 0.8763 (Best: 0.8790)
Epoch 10/200: Avg Val Loss: 1.7124, Avg Val Acc: 0.8747 (Best: 0.8866)
Current learning rate: [0.001]
Patience: 5/20
Epoch 11/200: Avg Train Loss: 1.6614, Avg Train Acc: 0.8743 (Best: 0.8790)
Epoch 11/200: Avg Val Loss: 1.7128, Avg Val Acc: 0.8902 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 12/200: Avg Train Loss: 1.6571, Avg Train Acc: 0.8865 (Best)
Epoch 12/200: Avg Val Loss: 1.7284, Avg Val Acc: 0.8746 (Best: 0.8902)
Current learning rate: [0.001]
Patience: 1/20
Epoch 13/200: Avg Train Loss: 1.6600, Avg Train Acc: 0.8792 (Best: 0.8865)
Epoch 13/200: Avg Val Loss: 1.6846, Avg Val Acc: 0.8486 (Best: 0.8902)
Current learning rate: [0.001]
Patience: 2/20
Epoch 14/200: Avg Train Loss: 1.6599, Avg Train Acc: 0.8833 (Best: 0.8865)
Epoch 14/200: Avg Val Loss: 1.7364, Avg Val Acc: 0.8370 (Best: 0.8902)
Current learning rate: [0.001]
Patience: 3/20
Epoch 15/200: Avg Train Loss: 1.6571, Avg Train Acc: 0.8763 (Best: 0.8865)
Epoch 15/200: Avg Val Loss: 1.7126, Avg Val Acc: 0.8847 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 4/20
Epoch 16/200: Avg Train Loss: 1.6591, Avg Train Acc: 0.8748 (Best: 0.8865)
Epoch 16/200: Avg Val Loss: 1.6990, Avg Val Acc: 0.8165 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 5/20
Epoch 17/200: Avg Train Loss: 1.6551, Avg Train Acc: 0.8818 (Best: 0.8865)
Epoch 17/200: Avg Val Loss: 1.7137, Avg Val Acc: 0.8785 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 6/20
Epoch 18/200: Avg Train Loss: 1.6543, Avg Train Acc: 0.8819 (Best: 0.8865)
Epoch 18/200: Avg Val Loss: 1.6920, Avg Val Acc: 0.8350 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 7/20
Epoch 19/200: Avg Train Loss: 1.6542, Avg Train Acc: 0.8849 (Best: 0.8865)
Epoch 19/200: Avg Val Loss: 1.7025, Avg Val Acc: 0.8446 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 8/20
Epoch 20/200: Avg Train Loss: 1.6504, Avg Train Acc: 0.8962 (Best)
Epoch 20/200: Avg Val Loss: 1.7075, Avg Val Acc: 0.8632 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 9/20
Epoch 21/200: Avg Train Loss: 1.6544, Avg Train Acc: 0.8897 (Best: 0.8962)
Epoch 21/200: Avg Val Loss: 1.6871, Avg Val Acc: 0.8805 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 10/20
Epoch 22/200: Avg Train Loss: 1.6542, Avg Train Acc: 0.8823 (Best: 0.8962)
Epoch 22/200: Avg Val Loss: 1.7297, Avg Val Acc: 0.8533 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 11/20
Epoch 23/200: Avg Train Loss: 1.6524, Avg Train Acc: 0.8871 (Best: 0.8962)
Epoch 23/200: Avg Val Loss: 1.7164, Avg Val Acc: 0.8439 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 24/200: Avg Train Loss: 1.6533, Avg Train Acc: 0.8900 (Best: 0.8962)
Epoch 24/200: Avg Val Loss: 1.6892, Avg Val Acc: 0.8580 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 25/200: Avg Train Loss: 1.6522, Avg Train Acc: 0.8833 (Best: 0.8962)
Epoch 25/200: Avg Val Loss: 1.6980, Avg Val Acc: 0.8519 (Best: 0.8902)
Current learning rate: [0.0005]
Patience: 14/20
Epoch 26/200: Avg Train Loss: 1.6536, Avg Train Acc: 0.8927 (Best: 0.8962)
Epoch 26/200: Avg Val Loss: 1.7127, Avg Val Acc: 0.8677 (Best: 0.8902)
Current learning rate: [0.00025]
Patience: 15/20
Epoch 27/200: Avg Train Loss: 1.6511, Avg Train Acc: 0.8890 (Best: 0.8962)
Epoch 27/200: Avg Val Loss: 1.7110, Avg Val Acc: 0.8521 (Best: 0.8902)
Current learning rate: [0.00025]
Patience: 16/20
Epoch 28/200: Avg Train Loss: 1.6482, Avg Train Acc: 0.8951 (Best: 0.8962)
Epoch 28/200: Avg Val Loss: 1.6962, Avg Val Acc: 0.8667 (Best: 0.8902)
Current learning rate: [0.00025]
Patience: 17/20
Epoch 29/200: Avg Train Loss: 1.6534, Avg Train Acc: 0.8887 (Best: 0.8962)
Epoch 29/200: Avg Val Loss: 1.7075, Avg Val Acc: 0.8540 (Best: 0.8902)
Current learning rate: [0.00025]
Patience: 18/20
Epoch 30/200: Avg Train Loss: 1.6484, Avg Train Acc: 0.8986 (Best)
Epoch 30/200: Avg Val Loss: 1.6992, Avg Val Acc: 0.8627 (Best: 0.8902)
Current learning rate: [0.00025]
Patience: 19/20
Epoch 31/200: Avg Train Loss: 1.6507, Avg Train Acc: 0.8918 (Best: 0.8986)
Epoch 31/200: Avg Val Loss: 1.6966, Avg Val Acc: 0.8766 (Best: 0.8902)
Current learning rate: [0.00025]
Early stopping in epoch 31
Finish training
