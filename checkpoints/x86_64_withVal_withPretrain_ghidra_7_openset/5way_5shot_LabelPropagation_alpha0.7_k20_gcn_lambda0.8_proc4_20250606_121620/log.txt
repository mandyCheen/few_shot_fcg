Device: cuda:4
Model: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: -0.1227, Avg Train Acc: 0.7069 (Best)
Open-Set AUROC: 0.6792
Epoch 1/200: Avg Val Loss: -0.1568, Avg Val Acc: 0.8865 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: -0.1803, Avg Train Acc: 0.9081 (Best)
Open-Set AUROC: 0.9298
Epoch 2/200: Avg Val Loss: -0.1710, Avg Val Acc: 0.9156 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: -0.1899, Avg Train Acc: 0.9244 (Best)
Open-Set AUROC: 0.9387
Epoch 3/200: Avg Val Loss: -0.1715, Avg Val Acc: 0.8853 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 4/200: Avg Train Loss: -0.2016, Avg Train Acc: 0.9263 (Best)
Open-Set AUROC: 0.9366
Epoch 4/200: Avg Val Loss: -0.1684, Avg Val Acc: 0.8831 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 2/20
Epoch 5/200: Avg Train Loss: -0.2020, Avg Train Acc: 0.9283 (Best)
Open-Set AUROC: 0.9485
Epoch 5/200: Avg Val Loss: -0.1680, Avg Val Acc: 0.8905 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 3/20
Epoch 6/200: Avg Train Loss: -0.2067, Avg Train Acc: 0.9295 (Best)
Open-Set AUROC: 0.9461
Epoch 6/200: Avg Val Loss: -0.1790, Avg Val Acc: 0.8948 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 4/20
Epoch 7/200: Avg Train Loss: -0.2078, Avg Train Acc: 0.9264 (Best: 0.9295)
Open-Set AUROC: 0.9491
Epoch 7/200: Avg Val Loss: -0.1655, Avg Val Acc: 0.8917 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 5/20
Epoch 8/200: Avg Train Loss: -0.2122, Avg Train Acc: 0.9375 (Best)
Open-Set AUROC: 0.9556
Epoch 8/200: Avg Val Loss: -0.1662, Avg Val Acc: 0.8885 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 6/20
Epoch 9/200: Avg Train Loss: -0.2076, Avg Train Acc: 0.9403 (Best)
Open-Set AUROC: 0.9557
Epoch 9/200: Avg Val Loss: -0.1336, Avg Val Acc: 0.8828 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 7/20
Epoch 10/200: Avg Train Loss: -0.2092, Avg Train Acc: 0.9327 (Best: 0.9403)
Open-Set AUROC: 0.9571
Epoch 10/200: Avg Val Loss: -0.1636, Avg Val Acc: 0.8936 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 8/20
Epoch 11/200: Avg Train Loss: -0.2075, Avg Train Acc: 0.9323 (Best: 0.9403)
Open-Set AUROC: 0.9573
Epoch 11/200: Avg Val Loss: -0.1622, Avg Val Acc: 0.8909 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 9/20
Epoch 12/200: Avg Train Loss: -0.2131, Avg Train Acc: 0.9388 (Best: 0.9403)
Open-Set AUROC: 0.9551
Epoch 12/200: Avg Val Loss: -0.1745, Avg Val Acc: 0.8943 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 10/20
Epoch 13/200: Avg Train Loss: -0.2146, Avg Train Acc: 0.9415 (Best)
Open-Set AUROC: 0.9590
Epoch 13/200: Avg Val Loss: -0.1601, Avg Val Acc: 0.8988 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 11/20
Epoch 14/200: Avg Train Loss: -0.2162, Avg Train Acc: 0.9341 (Best: 0.9415)
Open-Set AUROC: 0.9594
Epoch 14/200: Avg Val Loss: -0.1751, Avg Val Acc: 0.9031 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 12/20
Epoch 15/200: Avg Train Loss: -0.2138, Avg Train Acc: 0.9332 (Best: 0.9415)
Open-Set AUROC: 0.9530
Epoch 15/200: Avg Val Loss: -0.1776, Avg Val Acc: 0.9057 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 13/20
Epoch 16/200: Avg Train Loss: -0.2101, Avg Train Acc: 0.9281 (Best: 0.9415)
Open-Set AUROC: 0.9461
Epoch 16/200: Avg Val Loss: -0.1670, Avg Val Acc: 0.8883 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 14/20
Epoch 17/200: Avg Train Loss: -0.2155, Avg Train Acc: 0.9411 (Best: 0.9415)
Open-Set AUROC: 0.9613
Epoch 17/200: Avg Val Loss: -0.1731, Avg Val Acc: 0.8971 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 15/20
Epoch 18/200: Avg Train Loss: -0.2207, Avg Train Acc: 0.9493 (Best)
Open-Set AUROC: 0.9632
Epoch 18/200: Avg Val Loss: -0.1631, Avg Val Acc: 0.8764 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 16/20
Epoch 19/200: Avg Train Loss: -0.2220, Avg Train Acc: 0.9487 (Best: 0.9493)
Open-Set AUROC: 0.9667
Epoch 19/200: Avg Val Loss: -0.1714, Avg Val Acc: 0.8900 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 17/20
Epoch 20/200: Avg Train Loss: -0.2199, Avg Train Acc: 0.9511 (Best)
Open-Set AUROC: 0.9626
Epoch 20/200: Avg Val Loss: -0.1708, Avg Val Acc: 0.8847 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 18/20
Epoch 21/200: Avg Train Loss: -0.2224, Avg Train Acc: 0.9463 (Best: 0.9511)
Open-Set AUROC: 0.9616
Epoch 21/200: Avg Val Loss: -0.1630, Avg Val Acc: 0.8915 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 19/20
Epoch 22/200: Avg Train Loss: -0.2218, Avg Train Acc: 0.9460 (Best: 0.9511)
Open-Set AUROC: 0.9670
Epoch 22/200: Avg Val Loss: -0.1683, Avg Val Acc: 0.8944 (Best: 0.9156)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Early stopping in epoch 22
Finish training
