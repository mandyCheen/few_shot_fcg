Device: cuda:1
Model: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: -1.2671, Avg Train Acc: 0.7779 (Best)
Open-Set AUROC: 0.7509
Epoch 1/200: Avg Val Loss: -1.2978, Avg Val Acc: 0.8517 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: -1.3223, Avg Train Acc: 0.9232 (Best)
Open-Set AUROC: 0.9388
Epoch 2/200: Avg Val Loss: -1.3001, Avg Val Acc: 0.8677 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: -1.3289, Avg Train Acc: 0.9227 (Best: 0.9232)
Open-Set AUROC: 0.9418
Epoch 3/200: Avg Val Loss: -1.3090, Avg Val Acc: 0.8804 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: -1.3312, Avg Train Acc: 0.9372 (Best)
Open-Set AUROC: 0.9544
Epoch 4/200: Avg Val Loss: -1.3040, Avg Val Acc: 0.8429 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 5/200: Avg Train Loss: -1.3330, Avg Train Acc: 0.9259 (Best: 0.9372)
Open-Set AUROC: 0.9526
Epoch 5/200: Avg Val Loss: -1.2969, Avg Val Acc: 0.8507 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 2/20
Epoch 6/200: Avg Train Loss: -1.3360, Avg Train Acc: 0.9405 (Best)
Open-Set AUROC: 0.9540
Epoch 6/200: Avg Val Loss: -1.2934, Avg Val Acc: 0.8723 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 3/20
Epoch 7/200: Avg Train Loss: -1.3360, Avg Train Acc: 0.9401 (Best: 0.9405)
Open-Set AUROC: 0.9460
Epoch 7/200: Avg Val Loss: -1.3039, Avg Val Acc: 0.8601 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 4/20
Epoch 8/200: Avg Train Loss: -1.3388, Avg Train Acc: 0.9399 (Best: 0.9405)
Open-Set AUROC: 0.9566
Epoch 8/200: Avg Val Loss: -1.3040, Avg Val Acc: 0.8641 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 5/20
Epoch 9/200: Avg Train Loss: -1.3377, Avg Train Acc: 0.9469 (Best)
Open-Set AUROC: 0.9542
Epoch 9/200: Avg Val Loss: -1.2982, Avg Val Acc: 0.8531 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 6/20
Epoch 10/200: Avg Train Loss: -1.3405, Avg Train Acc: 0.9405 (Best: 0.9469)
Open-Set AUROC: 0.9550
Epoch 10/200: Avg Val Loss: -1.3070, Avg Val Acc: 0.8649 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 7/20
Epoch 11/200: Avg Train Loss: -1.3406, Avg Train Acc: 0.9532 (Best)
Open-Set AUROC: 0.9635
Epoch 11/200: Avg Val Loss: -1.3005, Avg Val Acc: 0.8605 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 8/20
Epoch 12/200: Avg Train Loss: -1.3333, Avg Train Acc: 0.9340 (Best: 0.9532)
Open-Set AUROC: 0.9549
Epoch 12/200: Avg Val Loss: -1.2968, Avg Val Acc: 0.8468 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 9/20
Epoch 13/200: Avg Train Loss: -1.3419, Avg Train Acc: 0.9404 (Best: 0.9532)
Open-Set AUROC: 0.9524
Epoch 13/200: Avg Val Loss: -1.3070, Avg Val Acc: 0.8721 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 10/20
Epoch 14/200: Avg Train Loss: -1.3398, Avg Train Acc: 0.9381 (Best: 0.9532)
Open-Set AUROC: 0.9549
Epoch 14/200: Avg Val Loss: -1.3089, Avg Val Acc: 0.8652 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 11/20
Epoch 15/200: Avg Train Loss: -1.3432, Avg Train Acc: 0.9401 (Best: 0.9532)
Open-Set AUROC: 0.9555
Epoch 15/200: Avg Val Loss: -1.3046, Avg Val Acc: 0.8660 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 12/20
Epoch 16/200: Avg Train Loss: -1.3399, Avg Train Acc: 0.9391 (Best: 0.9532)
Open-Set AUROC: 0.9562
Epoch 16/200: Avg Val Loss: -1.3106, Avg Val Acc: 0.8669 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 13/20
Epoch 17/200: Avg Train Loss: -1.3423, Avg Train Acc: 0.9437 (Best: 0.9532)
Open-Set AUROC: 0.9611
Epoch 17/200: Avg Val Loss: -1.3138, Avg Val Acc: 0.8725 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 14/20
Epoch 18/200: Avg Train Loss: -1.3432, Avg Train Acc: 0.9477 (Best: 0.9532)
Open-Set AUROC: 0.9649
Epoch 18/200: Avg Val Loss: -1.3097, Avg Val Acc: 0.8727 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 15/20
Epoch 19/200: Avg Train Loss: -1.3472, Avg Train Acc: 0.9493 (Best: 0.9532)
Open-Set AUROC: 0.9624
Epoch 19/200: Avg Val Loss: -1.3091, Avg Val Acc: 0.8525 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 16/20
Epoch 20/200: Avg Train Loss: -1.3476, Avg Train Acc: 0.9536 (Best)
Open-Set AUROC: 0.9634
Epoch 20/200: Avg Val Loss: -1.3060, Avg Val Acc: 0.8716 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 17/20
Epoch 21/200: Avg Train Loss: -1.3516, Avg Train Acc: 0.9563 (Best)
Open-Set AUROC: 0.9651
Epoch 21/200: Avg Val Loss: -1.3012, Avg Val Acc: 0.8456 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 18/20
Epoch 22/200: Avg Train Loss: -1.3423, Avg Train Acc: 0.9440 (Best: 0.9563)
Open-Set AUROC: 0.9587
Epoch 22/200: Avg Val Loss: -1.3010, Avg Val Acc: 0.8612 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 19/20
Epoch 23/200: Avg Train Loss: -1.3449, Avg Train Acc: 0.9377 (Best: 0.9563)
Open-Set AUROC: 0.9516
Epoch 23/200: Avg Val Loss: -1.2995, Avg Val Acc: 0.8427 (Best: 0.8804)
Open-Set AUROC: nan
Current learning rate: [0.001]
Early stopping in epoch 23
Finish training
