Device: cuda:1
Model: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GCNLayer(
      (gcn_convs): ModuleList(
        (0): GCNConv(128, 64)
        (1): GCNConv(64, 32)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GCNLayer(
      (gcn_convs): ModuleList(
        (0): GCNConv(128, 64)
        (1): GCNConv(64, 32)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: -2.2108, Avg Train Acc: 0.7185 (Best)
Open-Set AUROC: 0.6587
Epoch 1/200: Avg Val Loss: -2.2705, Avg Val Acc: 0.8972 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: -2.2906, Avg Train Acc: 0.9283 (Best)
Open-Set AUROC: 0.9349
Epoch 2/200: Avg Val Loss: -2.2861, Avg Val Acc: 0.8898 (Best: 0.8972)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 3/200: Avg Train Loss: -2.3047, Avg Train Acc: 0.9375 (Best)
Open-Set AUROC: 0.9515
Epoch 3/200: Avg Val Loss: -2.3014, Avg Val Acc: 0.9191 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: -2.3136, Avg Train Acc: 0.9451 (Best)
Open-Set AUROC: 0.9512
Epoch 4/200: Avg Val Loss: -2.2931, Avg Val Acc: 0.9237 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 5/200: Avg Train Loss: -2.3209, Avg Train Acc: 0.9500 (Best)
Open-Set AUROC: 0.9627
Epoch 5/200: Avg Val Loss: -2.3007, Avg Val Acc: 0.9005 (Best: 0.9237)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 6/200: Avg Train Loss: -2.3187, Avg Train Acc: 0.9474 (Best: 0.9500)
Open-Set AUROC: 0.9593
Epoch 6/200: Avg Val Loss: -2.3127, Avg Val Acc: 0.9266 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 7/200: Avg Train Loss: -2.3219, Avg Train Acc: 0.9480 (Best: 0.9500)
Open-Set AUROC: 0.9617
Epoch 7/200: Avg Val Loss: -2.2893, Avg Val Acc: 0.9152 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 8/200: Avg Train Loss: -2.3224, Avg Train Acc: 0.9428 (Best: 0.9500)
Open-Set AUROC: 0.9634
Epoch 8/200: Avg Val Loss: -2.3021, Avg Val Acc: 0.9222 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 2/20
Epoch 9/200: Avg Train Loss: -2.3294, Avg Train Acc: 0.9537 (Best)
Open-Set AUROC: 0.9665
Epoch 9/200: Avg Val Loss: -2.3007, Avg Val Acc: 0.9058 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 3/20
Epoch 10/200: Avg Train Loss: -2.3240, Avg Train Acc: 0.9535 (Best: 0.9537)
Open-Set AUROC: 0.9658
Epoch 10/200: Avg Val Loss: -2.2950, Avg Val Acc: 0.9134 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 4/20
Epoch 11/200: Avg Train Loss: -2.3302, Avg Train Acc: 0.9591 (Best)
Open-Set AUROC: 0.9685
Epoch 11/200: Avg Val Loss: -2.2835, Avg Val Acc: 0.8995 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 5/20
Epoch 12/200: Avg Train Loss: -2.3311, Avg Train Acc: 0.9531 (Best: 0.9591)
Open-Set AUROC: 0.9677
Epoch 12/200: Avg Val Loss: -2.3073, Avg Val Acc: 0.9211 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 6/20
Epoch 13/200: Avg Train Loss: -2.3286, Avg Train Acc: 0.9577 (Best: 0.9591)
Open-Set AUROC: 0.9680
Epoch 13/200: Avg Val Loss: -2.2872, Avg Val Acc: 0.8962 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 7/20
Epoch 14/200: Avg Train Loss: -2.3350, Avg Train Acc: 0.9594 (Best)
Open-Set AUROC: 0.9714
Epoch 14/200: Avg Val Loss: -2.3034, Avg Val Acc: 0.9097 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 8/20
Epoch 15/200: Avg Train Loss: -2.3338, Avg Train Acc: 0.9577 (Best: 0.9594)
Open-Set AUROC: 0.9702
Epoch 15/200: Avg Val Loss: -2.2959, Avg Val Acc: 0.9174 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 9/20
Epoch 16/200: Avg Train Loss: -2.3358, Avg Train Acc: 0.9538 (Best: 0.9594)
Open-Set AUROC: 0.9647
Epoch 16/200: Avg Val Loss: -2.2875, Avg Val Acc: 0.9182 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 10/20
Epoch 17/200: Avg Train Loss: -2.3405, Avg Train Acc: 0.9631 (Best)
Open-Set AUROC: 0.9806
Epoch 17/200: Avg Val Loss: -2.2975, Avg Val Acc: 0.9229 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 11/20
Epoch 18/200: Avg Train Loss: -2.3350, Avg Train Acc: 0.9562 (Best: 0.9631)
Open-Set AUROC: 0.9693
Epoch 18/200: Avg Val Loss: -2.2986, Avg Val Acc: 0.9166 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 12/20
Epoch 19/200: Avg Train Loss: -2.3400, Avg Train Acc: 0.9588 (Best: 0.9631)
Open-Set AUROC: 0.9693
Epoch 19/200: Avg Val Loss: -2.2943, Avg Val Acc: 0.9223 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 13/20
Epoch 20/200: Avg Train Loss: -2.3380, Avg Train Acc: 0.9589 (Best: 0.9631)
Open-Set AUROC: 0.9721
Epoch 20/200: Avg Val Loss: -2.2905, Avg Val Acc: 0.9051 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 14/20
Epoch 21/200: Avg Train Loss: -2.3409, Avg Train Acc: 0.9643 (Best)
Open-Set AUROC: 0.9713
Epoch 21/200: Avg Val Loss: -2.2903, Avg Val Acc: 0.9203 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 15/20
Epoch 22/200: Avg Train Loss: -2.3336, Avg Train Acc: 0.9557 (Best: 0.9643)
Open-Set AUROC: 0.9676
Epoch 22/200: Avg Val Loss: -2.3017, Avg Val Acc: 0.9222 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 16/20
Epoch 23/200: Avg Train Loss: -2.3390, Avg Train Acc: 0.9617 (Best: 0.9643)
Open-Set AUROC: 0.9753
Epoch 23/200: Avg Val Loss: -2.3032, Avg Val Acc: 0.9160 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 17/20
Epoch 24/200: Avg Train Loss: -2.3434, Avg Train Acc: 0.9588 (Best: 0.9643)
Open-Set AUROC: 0.9683
Epoch 24/200: Avg Val Loss: -2.2944, Avg Val Acc: 0.9158 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 18/20
Epoch 25/200: Avg Train Loss: -2.3431, Avg Train Acc: 0.9658 (Best)
Open-Set AUROC: 0.9759
Epoch 25/200: Avg Val Loss: -2.2998, Avg Val Acc: 0.9140 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 19/20
Epoch 26/200: Avg Train Loss: -2.3433, Avg Train Acc: 0.9595 (Best: 0.9658)
Open-Set AUROC: 0.9737
Epoch 26/200: Avg Val Loss: -2.3032, Avg Val Acc: 0.9058 (Best: 0.9266)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Early stopping in epoch 26
Finish training
