Pretrained model loaded from ./pretrained/x86_pretrained_GraphSAGE_3_layers_20250325_1459/epoch_83_0.971749856806638_best_backbone.pth
Device: cuda:0
Model: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.6967, Avg Train Acc: 0.7093 (Best)
Epoch 1/200: Avg Val Loss: 1.7037, Avg Val Acc: 0.7229 (Best)
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.6709, Avg Train Acc: 0.8299 (Best)
Epoch 2/200: Avg Val Loss: 1.6979, Avg Val Acc: 0.7392 (Best)
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.6695, Avg Train Acc: 0.8521 (Best)
Epoch 3/200: Avg Val Loss: 1.6971, Avg Val Acc: 0.7929 (Best)
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.6640, Avg Train Acc: 0.8680 (Best)
Epoch 4/200: Avg Val Loss: 1.6902, Avg Val Acc: 0.8245 (Best)
Patience: 0/20
Epoch 5/200: Avg Train Loss: 1.6602, Avg Train Acc: 0.8637 (Best: 0.8680)
Epoch 5/200: Avg Val Loss: 1.7044, Avg Val Acc: 0.8233 (Best: 0.8245)
Patience: 1/20
Epoch 6/200: Avg Train Loss: 1.6605, Avg Train Acc: 0.8659 (Best: 0.8680)
Epoch 6/200: Avg Val Loss: 1.7133, Avg Val Acc: 0.8091 (Best: 0.8245)
Patience: 2/20
Epoch 7/200: Avg Train Loss: 1.6599, Avg Train Acc: 0.8639 (Best: 0.8680)
Epoch 7/200: Avg Val Loss: 1.7145, Avg Val Acc: 0.7907 (Best: 0.8245)
Patience: 3/20
Epoch 8/200: Avg Train Loss: 1.6571, Avg Train Acc: 0.8733 (Best)
Epoch 8/200: Avg Val Loss: 1.7271, Avg Val Acc: 0.7871 (Best: 0.8245)
Patience: 4/20
Epoch 9/200: Avg Train Loss: 1.6548, Avg Train Acc: 0.8877 (Best)
Epoch 9/200: Avg Val Loss: 1.7206, Avg Val Acc: 0.7896 (Best: 0.8245)
Patience: 5/20
Epoch 10/200: Avg Train Loss: 1.6540, Avg Train Acc: 0.8709 (Best: 0.8877)
Epoch 10/200: Avg Val Loss: 1.7242, Avg Val Acc: 0.7879 (Best: 0.8245)
Patience: 6/20
Epoch 11/200: Avg Train Loss: 1.6541, Avg Train Acc: 0.8843 (Best: 0.8877)
Epoch 11/200: Avg Val Loss: 1.7175, Avg Val Acc: 0.7929 (Best: 0.8245)
Patience: 7/20
Epoch 12/200: Avg Train Loss: 1.6530, Avg Train Acc: 0.8867 (Best: 0.8877)
Epoch 12/200: Avg Val Loss: 1.6962, Avg Val Acc: 0.8129 (Best: 0.8245)
Patience: 8/20
Epoch 13/200: Avg Train Loss: 1.6535, Avg Train Acc: 0.8849 (Best: 0.8877)
Epoch 13/200: Avg Val Loss: 1.6863, Avg Val Acc: 0.7977 (Best: 0.8245)
Patience: 9/20
Epoch 14/200: Avg Train Loss: 1.6520, Avg Train Acc: 0.8813 (Best: 0.8877)
Epoch 14/200: Avg Val Loss: 1.7197, Avg Val Acc: 0.7939 (Best: 0.8245)
Patience: 10/20
Epoch 15/200: Avg Train Loss: 1.6511, Avg Train Acc: 0.8871 (Best: 0.8877)
Epoch 15/200: Avg Val Loss: 1.6883, Avg Val Acc: 0.8155 (Best: 0.8245)
Patience: 11/20
Epoch 16/200: Avg Train Loss: 1.6510, Avg Train Acc: 0.8813 (Best: 0.8877)
Epoch 16/200: Avg Val Loss: 1.6999, Avg Val Acc: 0.8051 (Best: 0.8245)
Patience: 12/20
Epoch 17/200: Avg Train Loss: 1.6481, Avg Train Acc: 0.8953 (Best)
Epoch 17/200: Avg Val Loss: 1.7424, Avg Val Acc: 0.7603 (Best: 0.8245)
Patience: 13/20
Epoch 18/200: Avg Train Loss: 1.6495, Avg Train Acc: 0.8836 (Best: 0.8953)
Epoch 18/200: Avg Val Loss: 1.6859, Avg Val Acc: 0.8091 (Best: 0.8245)
Patience: 14/20
Epoch 19/200: Avg Train Loss: 1.6507, Avg Train Acc: 0.8896 (Best: 0.8953)
Epoch 19/200: Avg Val Loss: 1.7120, Avg Val Acc: 0.7895 (Best: 0.8245)
Patience: 15/20
Epoch 20/200: Avg Train Loss: 1.6498, Avg Train Acc: 0.8814 (Best: 0.8953)
Epoch 20/200: Avg Val Loss: 1.7108, Avg Val Acc: 0.7903 (Best: 0.8245)
Patience: 16/20
Epoch 21/200: Avg Train Loss: 1.6503, Avg Train Acc: 0.8818 (Best: 0.8953)
Epoch 21/200: Avg Val Loss: 1.7204, Avg Val Acc: 0.8025 (Best: 0.8245)
Patience: 17/20
Epoch 22/200: Avg Train Loss: 1.6482, Avg Train Acc: 0.8906 (Best: 0.8953)
Epoch 22/200: Avg Val Loss: 1.7018, Avg Val Acc: 0.8045 (Best: 0.8245)
Patience: 18/20
Epoch 23/200: Avg Train Loss: 1.6481, Avg Train Acc: 0.8908 (Best: 0.8953)
Epoch 23/200: Avg Val Loss: 1.7299, Avg Val Acc: 0.7773 (Best: 0.8245)
Patience: 19/20
Epoch 24/200: Avg Train Loss: 1.6463, Avg Train Acc: 0.8947 (Best: 0.8953)
Epoch 24/200: Avg Val Loss: 1.7101, Avg Val Acc: 0.8003 (Best: 0.8245)
Early stopping in epoch 24
Finish training
