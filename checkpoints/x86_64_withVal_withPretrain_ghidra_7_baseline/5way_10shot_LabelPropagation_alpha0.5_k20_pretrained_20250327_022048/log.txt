Pretrained model loaded from ./pretrained/x86_pretrained_GraphSAGE_3_layers_20250325_1459/epoch_83_0.971749856806638_best_backbone.pth
Device: cuda:0
Model: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 0.9845, Avg Train Acc: 0.7502 (Best)
Epoch 1/200: Avg Val Loss: 0.9744, Avg Val Acc: 0.9130 (Best)
Patience: 0/20
Epoch 2/200: Avg Train Loss: 0.9675, Avg Train Acc: 0.8890 (Best)
Epoch 2/200: Avg Val Loss: 0.9899, Avg Val Acc: 0.8912 (Best: 0.9130)
Patience: 1/20
Epoch 3/200: Avg Train Loss: 0.9643, Avg Train Acc: 0.9150 (Best)
Epoch 3/200: Avg Val Loss: 0.9761, Avg Val Acc: 0.9228 (Best)
Patience: 0/20
Epoch 4/200: Avg Train Loss: 0.9629, Avg Train Acc: 0.9224 (Best)
Epoch 4/200: Avg Val Loss: 0.9964, Avg Val Acc: 0.8836 (Best: 0.9228)
Patience: 1/20
Epoch 5/200: Avg Train Loss: 0.9626, Avg Train Acc: 0.9214 (Best: 0.9224)
Epoch 5/200: Avg Val Loss: 0.9857, Avg Val Acc: 0.9002 (Best: 0.9228)
Patience: 2/20
Epoch 6/200: Avg Train Loss: 0.9596, Avg Train Acc: 0.9260 (Best)
Epoch 6/200: Avg Val Loss: 0.9872, Avg Val Acc: 0.8964 (Best: 0.9228)
Patience: 3/20
Epoch 7/200: Avg Train Loss: 0.9595, Avg Train Acc: 0.9244 (Best: 0.9260)
Epoch 7/200: Avg Val Loss: 0.9908, Avg Val Acc: 0.8846 (Best: 0.9228)
Patience: 4/20
Epoch 8/200: Avg Train Loss: 0.9624, Avg Train Acc: 0.9176 (Best: 0.9260)
Epoch 8/200: Avg Val Loss: 0.9927, Avg Val Acc: 0.8862 (Best: 0.9228)
Patience: 5/20
Epoch 9/200: Avg Train Loss: 0.9592, Avg Train Acc: 0.9262 (Best)
Epoch 9/200: Avg Val Loss: 0.9880, Avg Val Acc: 0.8996 (Best: 0.9228)
Patience: 6/20
Epoch 10/200: Avg Train Loss: 0.9567, Avg Train Acc: 0.9326 (Best)
Epoch 10/200: Avg Val Loss: 0.9939, Avg Val Acc: 0.8882 (Best: 0.9228)
Patience: 7/20
Epoch 11/200: Avg Train Loss: 0.9597, Avg Train Acc: 0.9384 (Best)
Epoch 11/200: Avg Val Loss: 0.9901, Avg Val Acc: 0.8920 (Best: 0.9228)
Patience: 8/20
Epoch 12/200: Avg Train Loss: 0.9601, Avg Train Acc: 0.9298 (Best: 0.9384)
Epoch 12/200: Avg Val Loss: 0.9806, Avg Val Acc: 0.8974 (Best: 0.9228)
Patience: 9/20
Epoch 13/200: Avg Train Loss: 0.9587, Avg Train Acc: 0.9350 (Best: 0.9384)
Epoch 13/200: Avg Val Loss: 0.9898, Avg Val Acc: 0.8908 (Best: 0.9228)
Patience: 10/20
Epoch 14/200: Avg Train Loss: 0.9578, Avg Train Acc: 0.9264 (Best: 0.9384)
Epoch 14/200: Avg Val Loss: 0.9908, Avg Val Acc: 0.8836 (Best: 0.9228)
Patience: 11/20
Epoch 15/200: Avg Train Loss: 0.9583, Avg Train Acc: 0.9216 (Best: 0.9384)
Epoch 15/200: Avg Val Loss: 0.9875, Avg Val Acc: 0.8904 (Best: 0.9228)
Patience: 12/20
Epoch 16/200: Avg Train Loss: 0.9570, Avg Train Acc: 0.9336 (Best: 0.9384)
Epoch 16/200: Avg Val Loss: 0.9945, Avg Val Acc: 0.8798 (Best: 0.9228)
Patience: 13/20
Epoch 17/200: Avg Train Loss: 0.9564, Avg Train Acc: 0.9258 (Best: 0.9384)
Epoch 17/200: Avg Val Loss: 0.9905, Avg Val Acc: 0.8860 (Best: 0.9228)
Patience: 14/20
Epoch 18/200: Avg Train Loss: 0.9557, Avg Train Acc: 0.9416 (Best)
Epoch 18/200: Avg Val Loss: 0.9920, Avg Val Acc: 0.8816 (Best: 0.9228)
Patience: 15/20
Epoch 19/200: Avg Train Loss: 0.9560, Avg Train Acc: 0.9328 (Best: 0.9416)
Epoch 19/200: Avg Val Loss: 0.9946, Avg Val Acc: 0.8916 (Best: 0.9228)
Patience: 16/20
Epoch 20/200: Avg Train Loss: 0.9576, Avg Train Acc: 0.9328 (Best: 0.9416)
Epoch 20/200: Avg Val Loss: 0.9937, Avg Val Acc: 0.8776 (Best: 0.9228)
Patience: 17/20
Epoch 21/200: Avg Train Loss: 0.9574, Avg Train Acc: 0.9380 (Best: 0.9416)
Epoch 21/200: Avg Val Loss: 0.9940, Avg Val Acc: 0.8754 (Best: 0.9228)
Patience: 18/20
Epoch 22/200: Avg Train Loss: 0.9572, Avg Train Acc: 0.9338 (Best: 0.9416)
Epoch 22/200: Avg Val Loss: 0.9886, Avg Val Acc: 0.8838 (Best: 0.9228)
Patience: 19/20
Epoch 23/200: Avg Train Loss: 0.9568, Avg Train Acc: 0.9344 (Best: 0.9416)
Epoch 23/200: Avg Val Loss: 0.9913, Avg Val Acc: 0.8818 (Best: 0.9228)
Early stopping in epoch 23
Finish training
