Device: cuda:0
Model: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 0.6422, Avg Train Acc: 0.1373 (Best)
Open-Set AUROC: 0.0925
Epoch 1/200: Avg Val Loss: 0.6281, Avg Val Acc: 0.1427 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 0.6306, Avg Train Acc: 0.1951 (Best)
Open-Set AUROC: 0.1603
Epoch 2/200: Avg Val Loss: 0.6327, Avg Val Acc: 0.1491 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 0.5976, Avg Train Acc: 0.5037 (Best)
Open-Set AUROC: 0.5146
Epoch 3/200: Avg Val Loss: 0.5663, Avg Val Acc: 0.5221 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 0.5671, Avg Train Acc: 0.6499 (Best)
Open-Set AUROC: 0.6748
Epoch 4/200: Avg Val Loss: 0.5275, Avg Val Acc: 0.8504 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 5/200: Avg Train Loss: 0.5490, Avg Train Acc: 0.8040 (Best)
Open-Set AUROC: 0.8673
Epoch 5/200: Avg Val Loss: 0.5263, Avg Val Acc: 0.8703 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 6/200: Avg Train Loss: 0.5411, Avg Train Acc: 0.8337 (Best)
Open-Set AUROC: 0.8875
Epoch 6/200: Avg Val Loss: 0.5169, Avg Val Acc: 0.8728 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 7/200: Avg Train Loss: 0.5338, Avg Train Acc: 0.8402 (Best)
Open-Set AUROC: 0.8923
Epoch 7/200: Avg Val Loss: 0.5176, Avg Val Acc: 0.8685 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 8/200: Avg Train Loss: 0.5307, Avg Train Acc: 0.8501 (Best)
Open-Set AUROC: 0.9029
Epoch 8/200: Avg Val Loss: 0.5194, Avg Val Acc: 0.8454 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 2/20
Epoch 9/200: Avg Train Loss: 0.5293, Avg Train Acc: 0.8497 (Best: 0.8501)
Open-Set AUROC: 0.9043
Epoch 9/200: Avg Val Loss: 0.5285, Avg Val Acc: 0.8485 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 3/20
Epoch 10/200: Avg Train Loss: 0.5244, Avg Train Acc: 0.8565 (Best)
Open-Set AUROC: 0.9081
Epoch 10/200: Avg Val Loss: 0.5250, Avg Val Acc: 0.8589 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 4/20
Epoch 11/200: Avg Train Loss: 0.5272, Avg Train Acc: 0.8697 (Best)
Open-Set AUROC: 0.9133
Epoch 11/200: Avg Val Loss: 0.5259, Avg Val Acc: 0.8560 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 5/20
Epoch 12/200: Avg Train Loss: 0.5232, Avg Train Acc: 0.8697 (Best)
Open-Set AUROC: 0.9139
Epoch 12/200: Avg Val Loss: 0.5262, Avg Val Acc: 0.8595 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 6/20
Epoch 13/200: Avg Train Loss: 0.5214, Avg Train Acc: 0.8685 (Best: 0.8697)
Open-Set AUROC: 0.9168
Epoch 13/200: Avg Val Loss: 0.5290, Avg Val Acc: 0.8461 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 7/20
Epoch 14/200: Avg Train Loss: 0.5217, Avg Train Acc: 0.8667 (Best: 0.8697)
Open-Set AUROC: 0.9245
Epoch 14/200: Avg Val Loss: 0.5323, Avg Val Acc: 0.8509 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 8/20
Epoch 15/200: Avg Train Loss: 0.5188, Avg Train Acc: 0.8663 (Best: 0.8697)
Open-Set AUROC: 0.9207
Epoch 15/200: Avg Val Loss: 0.5319, Avg Val Acc: 0.8433 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 9/20
Epoch 16/200: Avg Train Loss: 0.5215, Avg Train Acc: 0.8688 (Best: 0.8697)
Open-Set AUROC: 0.9209
Epoch 16/200: Avg Val Loss: 0.5401, Avg Val Acc: 0.8247 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 10/20
Epoch 17/200: Avg Train Loss: 0.5202, Avg Train Acc: 0.8763 (Best)
Open-Set AUROC: 0.9227
Epoch 17/200: Avg Val Loss: 0.5355, Avg Val Acc: 0.8265 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 11/20
Epoch 18/200: Avg Train Loss: 0.5142, Avg Train Acc: 0.8743 (Best: 0.8763)
Open-Set AUROC: 0.9284
Epoch 18/200: Avg Val Loss: 0.5378, Avg Val Acc: 0.8582 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 12/20
Epoch 19/200: Avg Train Loss: 0.5170, Avg Train Acc: 0.8790 (Best)
Open-Set AUROC: 0.9277
Epoch 19/200: Avg Val Loss: 0.5336, Avg Val Acc: 0.8401 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 13/20
Epoch 20/200: Avg Train Loss: 0.5124, Avg Train Acc: 0.8811 (Best)
Open-Set AUROC: 0.9329
Epoch 20/200: Avg Val Loss: 0.5360, Avg Val Acc: 0.8503 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 14/20
Epoch 21/200: Avg Train Loss: 0.5140, Avg Train Acc: 0.8810 (Best: 0.8811)
Open-Set AUROC: 0.9315
Epoch 21/200: Avg Val Loss: 0.5329, Avg Val Acc: 0.8507 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 15/20
Epoch 22/200: Avg Train Loss: 0.5119, Avg Train Acc: 0.8809 (Best: 0.8811)
Open-Set AUROC: 0.9314
Epoch 22/200: Avg Val Loss: 0.5298, Avg Val Acc: 0.8519 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 16/20
Epoch 23/200: Avg Train Loss: 0.5104, Avg Train Acc: 0.8806 (Best: 0.8811)
Open-Set AUROC: 0.9296
Epoch 23/200: Avg Val Loss: 0.5377, Avg Val Acc: 0.8550 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 17/20
Epoch 24/200: Avg Train Loss: 0.5119, Avg Train Acc: 0.8909 (Best)
Open-Set AUROC: 0.9302
Epoch 24/200: Avg Val Loss: 0.5423, Avg Val Acc: 0.8513 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 18/20
Epoch 25/200: Avg Train Loss: 0.5121, Avg Train Acc: 0.8861 (Best: 0.8909)
Open-Set AUROC: 0.9341
Epoch 25/200: Avg Val Loss: 0.5402, Avg Val Acc: 0.8537 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 19/20
Epoch 26/200: Avg Train Loss: 0.5121, Avg Train Acc: 0.8829 (Best: 0.8909)
Open-Set AUROC: 0.9341
Epoch 26/200: Avg Val Loss: 0.5361, Avg Val Acc: 0.8447 (Best: 0.8728)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Early stopping in epoch 26
Finish training
