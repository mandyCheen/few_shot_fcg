Device: cuda:0
Model: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GCNLayer(
    (gcn_convs): ModuleList(
      (0): GCNConv(128, 256)
      (1): GCNConv(256, 256)
      (2): GCNConv(256, 128)
    )
    (norms): ModuleList(
      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (block): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: -0.7398, Avg Train Acc: 0.2122 (Best)
Open-Set AUROC: 0.0168
Epoch 1/200: Avg Val Loss: -0.7526, Avg Val Acc: 0.2402 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: -0.7535, Avg Train Acc: 0.2594 (Best)
Open-Set AUROC: 0.0968
Epoch 2/200: Avg Val Loss: -0.8264, Avg Val Acc: 0.5976 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: -0.8807, Avg Train Acc: 0.8374 (Best)
Open-Set AUROC: 0.8207
Epoch 3/200: Avg Val Loss: -0.9081, Avg Val Acc: 0.9156 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: -0.9235, Avg Train Acc: 0.9256 (Best)
Open-Set AUROC: 0.9415
Epoch 4/200: Avg Val Loss: -0.9176, Avg Val Acc: 0.9304 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 5/200: Avg Train Loss: -0.9428, Avg Train Acc: 0.9432 (Best)
Open-Set AUROC: 0.9508
Epoch 5/200: Avg Val Loss: -0.9154, Avg Val Acc: 0.9178 (Best: 0.9304)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 6/200: Avg Train Loss: -0.9446, Avg Train Acc: 0.9464 (Best)
Open-Set AUROC: 0.9507
Epoch 6/200: Avg Val Loss: -0.9220, Avg Val Acc: 0.9482 (Best)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 0/20
Epoch 7/200: Avg Train Loss: -0.9440, Avg Train Acc: 0.9468 (Best)
Open-Set AUROC: 0.9520
Epoch 7/200: Avg Val Loss: -0.9225, Avg Val Acc: 0.9216 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 1/20
Epoch 8/200: Avg Train Loss: -0.9538, Avg Train Acc: 0.9506 (Best)
Open-Set AUROC: 0.9612
Epoch 8/200: Avg Val Loss: -0.9327, Avg Val Acc: 0.9358 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 2/20
Epoch 9/200: Avg Train Loss: -0.9502, Avg Train Acc: 0.9394 (Best: 0.9506)
Open-Set AUROC: 0.9519
Epoch 9/200: Avg Val Loss: -0.9231, Avg Val Acc: 0.9336 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 3/20
Epoch 10/200: Avg Train Loss: -0.9479, Avg Train Acc: 0.9510 (Best)
Open-Set AUROC: 0.9590
Epoch 10/200: Avg Val Loss: -0.9262, Avg Val Acc: 0.9300 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 4/20
Epoch 11/200: Avg Train Loss: -0.9535, Avg Train Acc: 0.9476 (Best: 0.9510)
Open-Set AUROC: 0.9540
Epoch 11/200: Avg Val Loss: -0.9261, Avg Val Acc: 0.9326 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 5/20
Epoch 12/200: Avg Train Loss: -0.9549, Avg Train Acc: 0.9472 (Best: 0.9510)
Open-Set AUROC: 0.9571
Epoch 12/200: Avg Val Loss: -0.9261, Avg Val Acc: 0.9242 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 6/20
Epoch 13/200: Avg Train Loss: -0.9600, Avg Train Acc: 0.9514 (Best)
Open-Set AUROC: 0.9640
Epoch 13/200: Avg Val Loss: -0.9186, Avg Val Acc: 0.9282 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 7/20
Epoch 14/200: Avg Train Loss: -0.9534, Avg Train Acc: 0.9476 (Best: 0.9514)
Open-Set AUROC: 0.9538
Epoch 14/200: Avg Val Loss: -0.9313, Avg Val Acc: 0.9366 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 8/20
Epoch 15/200: Avg Train Loss: -0.9594, Avg Train Acc: 0.9476 (Best: 0.9514)
Open-Set AUROC: 0.9607
Epoch 15/200: Avg Val Loss: -0.9273, Avg Val Acc: 0.9396 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 9/20
Epoch 16/200: Avg Train Loss: -0.9617, Avg Train Acc: 0.9516 (Best)
Open-Set AUROC: 0.9606
Epoch 16/200: Avg Val Loss: -0.9241, Avg Val Acc: 0.9280 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 10/20
Epoch 17/200: Avg Train Loss: -0.9607, Avg Train Acc: 0.9558 (Best)
Open-Set AUROC: 0.9610
Epoch 17/200: Avg Val Loss: -0.9314, Avg Val Acc: 0.9404 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 11/20
Epoch 18/200: Avg Train Loss: -0.9563, Avg Train Acc: 0.9446 (Best: 0.9558)
Open-Set AUROC: 0.9596
Epoch 18/200: Avg Val Loss: -0.9315, Avg Val Acc: 0.9284 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.001]
Patience: 12/20
Epoch 19/200: Avg Train Loss: -0.9617, Avg Train Acc: 0.9530 (Best: 0.9558)
Open-Set AUROC: 0.9664
Epoch 19/200: Avg Val Loss: -0.9172, Avg Val Acc: 0.9270 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 13/20
Epoch 20/200: Avg Train Loss: -0.9610, Avg Train Acc: 0.9498 (Best: 0.9558)
Open-Set AUROC: 0.9592
Epoch 20/200: Avg Val Loss: -0.9281, Avg Val Acc: 0.9322 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 14/20
Epoch 21/200: Avg Train Loss: -0.9689, Avg Train Acc: 0.9568 (Best)
Open-Set AUROC: 0.9693
Epoch 21/200: Avg Val Loss: -0.9250, Avg Val Acc: 0.9244 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 15/20
Epoch 22/200: Avg Train Loss: -0.9659, Avg Train Acc: 0.9502 (Best: 0.9568)
Open-Set AUROC: 0.9628
Epoch 22/200: Avg Val Loss: -0.9265, Avg Val Acc: 0.9342 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 16/20
Epoch 23/200: Avg Train Loss: -0.9698, Avg Train Acc: 0.9592 (Best)
Open-Set AUROC: 0.9668
Epoch 23/200: Avg Val Loss: -0.9248, Avg Val Acc: 0.9246 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 17/20
Epoch 24/200: Avg Train Loss: -0.9690, Avg Train Acc: 0.9596 (Best)
Open-Set AUROC: 0.9711
Epoch 24/200: Avg Val Loss: -0.9246, Avg Val Acc: 0.9304 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 18/20
Epoch 25/200: Avg Train Loss: -0.9740, Avg Train Acc: 0.9638 (Best)
Open-Set AUROC: 0.9702
Epoch 25/200: Avg Val Loss: -0.9286, Avg Val Acc: 0.9252 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 19/20
Epoch 26/200: Avg Train Loss: -0.9649, Avg Train Acc: 0.9548 (Best: 0.9638)
Open-Set AUROC: 0.9661
Epoch 26/200: Avg Val Loss: -0.9205, Avg Val Acc: 0.9220 (Best: 0.9482)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Early stopping in epoch 26
Finish training
