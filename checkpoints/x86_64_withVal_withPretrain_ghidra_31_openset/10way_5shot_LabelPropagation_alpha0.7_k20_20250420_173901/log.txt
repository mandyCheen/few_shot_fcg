Device: cuda:0
Model loaded from /home/mandy/Projects/few_shot_fcg/checkpoints/x86_64_withVal_withPretrain_ghidra_7_baseline/5way_5shot_LabelPropagation_alpha0.7_k20_20250315_175358/epoch_13_0.8993333566188813_best.pth
Model: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GraphSAGELayer(
    (sage_convs): ModuleList(
      (0-2): 3 x SAGEConv(128, 128, aggr=mean)
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (relation): GraphRelationNetwork(
    (sage): GraphSAGELayer(
      (sage_convs): ModuleList(
        (0): SAGEConv(128, 64, aggr=mean)
        (1): SAGEConv(64, 32, aggr=mean)
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 0.5160, Avg Train Acc: 0.8611 (Best)
Open-Set AUROC: 0.8881
Epoch 1/200: Avg Val Loss: 0.5128, Avg Val Acc: 0.8694 (Best)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 0.5080, Avg Train Acc: 0.8716 (Best)
Open-Set AUROC: 0.9020
Epoch 2/200: Avg Val Loss: 0.5028, Avg Val Acc: 0.8961 (Best)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 0.5065, Avg Train Acc: 0.8748 (Best)
Open-Set AUROC: 0.9025
Epoch 3/200: Avg Val Loss: 0.5060, Avg Val Acc: 0.8950 (Best: 0.8961)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 1/20
Epoch 4/200: Avg Train Loss: 0.5008, Avg Train Acc: 0.8877 (Best)
Open-Set AUROC: 0.9117
Epoch 4/200: Avg Val Loss: 0.5054, Avg Val Acc: 0.9091 (Best)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 0/20
Epoch 5/200: Avg Train Loss: 0.5034, Avg Train Acc: 0.8704 (Best: 0.8877)
Open-Set AUROC: 0.9077
Epoch 5/200: Avg Val Loss: 0.5042, Avg Val Acc: 0.9003 (Best: 0.9091)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 1/20
Epoch 6/200: Avg Train Loss: 0.4990, Avg Train Acc: 0.8895 (Best)
Open-Set AUROC: 0.9190
Epoch 6/200: Avg Val Loss: 0.5019, Avg Val Acc: 0.9144 (Best)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 0/20
Epoch 7/200: Avg Train Loss: 0.4991, Avg Train Acc: 0.8916 (Best)
Open-Set AUROC: 0.9189
Epoch 7/200: Avg Val Loss: 0.5053, Avg Val Acc: 0.8945 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 1/20
Epoch 8/200: Avg Train Loss: 0.4982, Avg Train Acc: 0.8842 (Best: 0.8916)
Open-Set AUROC: 0.9128
Epoch 8/200: Avg Val Loss: 0.5040, Avg Val Acc: 0.9049 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 2/20
Epoch 9/200: Avg Train Loss: 0.4961, Avg Train Acc: 0.8895 (Best: 0.8916)
Open-Set AUROC: 0.9210
Epoch 9/200: Avg Val Loss: 0.5030, Avg Val Acc: 0.9059 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 3/20
Epoch 10/200: Avg Train Loss: 0.4983, Avg Train Acc: 0.8883 (Best: 0.8916)
Open-Set AUROC: 0.9227
Epoch 10/200: Avg Val Loss: 0.5050, Avg Val Acc: 0.9070 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 4/20
Epoch 11/200: Avg Train Loss: 0.4945, Avg Train Acc: 0.8937 (Best)
Open-Set AUROC: 0.9228
Epoch 11/200: Avg Val Loss: 0.5032, Avg Val Acc: 0.9143 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 5/20
Epoch 12/200: Avg Train Loss: 0.4962, Avg Train Acc: 0.8889 (Best: 0.8937)
Open-Set AUROC: 0.9203
Epoch 12/200: Avg Val Loss: 0.5043, Avg Val Acc: 0.8993 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 6/20
Epoch 13/200: Avg Train Loss: 0.4936, Avg Train Acc: 0.8899 (Best: 0.8937)
Open-Set AUROC: 0.9230
Epoch 13/200: Avg Val Loss: 0.5012, Avg Val Acc: 0.8980 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 7/20
Epoch 14/200: Avg Train Loss: 0.4944, Avg Train Acc: 0.8891 (Best: 0.8937)
Open-Set AUROC: 0.9197
Epoch 14/200: Avg Val Loss: 0.5031, Avg Val Acc: 0.8893 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 8/20
Epoch 15/200: Avg Train Loss: 0.4915, Avg Train Acc: 0.9023 (Best)
Open-Set AUROC: 0.9252
Epoch 15/200: Avg Val Loss: 0.5016, Avg Val Acc: 0.9037 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 9/20
Epoch 16/200: Avg Train Loss: 0.4942, Avg Train Acc: 0.8857 (Best: 0.9023)
Open-Set AUROC: 0.9214
Epoch 16/200: Avg Val Loss: 0.5054, Avg Val Acc: 0.9069 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 10/20
Epoch 17/200: Avg Train Loss: 0.4923, Avg Train Acc: 0.8895 (Best: 0.9023)
Open-Set AUROC: 0.9200
Epoch 17/200: Avg Val Loss: 0.5024, Avg Val Acc: 0.8921 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 11/20
Epoch 18/200: Avg Train Loss: 0.4943, Avg Train Acc: 0.8797 (Best: 0.9023)
Open-Set AUROC: 0.9132
Epoch 18/200: Avg Val Loss: 0.5048, Avg Val Acc: 0.8879 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 12/20
Epoch 19/200: Avg Train Loss: 0.4928, Avg Train Acc: 0.8914 (Best: 0.9023)
Open-Set AUROC: 0.9233
Epoch 19/200: Avg Val Loss: 0.4999, Avg Val Acc: 0.8971 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 13/20
Epoch 20/200: Avg Train Loss: 0.4924, Avg Train Acc: 0.8909 (Best: 0.9023)
Open-Set AUROC: 0.9199
Epoch 20/200: Avg Val Loss: 0.5021, Avg Val Acc: 0.8995 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 14/20
Epoch 21/200: Avg Train Loss: 0.4912, Avg Train Acc: 0.9007 (Best: 0.9023)
Open-Set AUROC: 0.9255
Epoch 21/200: Avg Val Loss: 0.4997, Avg Val Acc: 0.9132 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 15/20
Epoch 22/200: Avg Train Loss: 0.4905, Avg Train Acc: 0.8929 (Best: 0.9023)
Open-Set AUROC: 0.9226
Epoch 22/200: Avg Val Loss: 0.4993, Avg Val Acc: 0.9069 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 16/20
Epoch 23/200: Avg Train Loss: 0.4902, Avg Train Acc: 0.8935 (Best: 0.9023)
Open-Set AUROC: 0.9210
Epoch 23/200: Avg Val Loss: 0.5018, Avg Val Acc: 0.8881 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 17/20
Epoch 24/200: Avg Train Loss: 0.4893, Avg Train Acc: 0.8883 (Best: 0.9023)
Open-Set AUROC: 0.9215
Epoch 24/200: Avg Val Loss: 0.5035, Avg Val Acc: 0.9065 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 18/20
Epoch 25/200: Avg Train Loss: 0.4915, Avg Train Acc: 0.8875 (Best: 0.9023)
Open-Set AUROC: 0.9184
Epoch 25/200: Avg Val Loss: 0.5015, Avg Val Acc: 0.8993 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Patience: 19/20
Epoch 26/200: Avg Train Loss: 0.4903, Avg Train Acc: 0.8898 (Best: 0.9023)
Open-Set AUROC: 0.9194
Epoch 26/200: Avg Val Loss: 0.5021, Avg Val Acc: 0.8865 (Best: 0.9144)
Open-Set AUROC: nan
Current learning rate: [0.0005]
Early stopping in epoch 26
Finish training
