Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.6939, Avg Train Acc: 0.8208 (Best)
Epoch 1/200: Avg Val Loss: 1.7461, Avg Val Acc: 0.7996 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.6870, Avg Train Acc: 0.8104 (Best: 0.8208)
Epoch 2/200: Avg Val Loss: 1.7173, Avg Val Acc: 0.8133 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.6860, Avg Train Acc: 0.8012 (Best: 0.8208)
Epoch 3/200: Avg Val Loss: 1.7286, Avg Val Acc: 0.8271 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.6831, Avg Train Acc: 0.8082 (Best: 0.8208)
Epoch 4/200: Avg Val Loss: 1.7174, Avg Val Acc: 0.8383 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 5/200: Avg Train Loss: 1.6803, Avg Train Acc: 0.8291 (Best)
Epoch 5/200: Avg Val Loss: 1.7061, Avg Val Acc: 0.8377 (Best: 0.8383)
Current learning rate: [0.001]
Patience: 1/20
Epoch 6/200: Avg Train Loss: 1.6721, Avg Train Acc: 0.8427 (Best)
Epoch 6/200: Avg Val Loss: 1.6936, Avg Val Acc: 0.7751 (Best: 0.8383)
Current learning rate: [0.001]
Patience: 2/20
Epoch 7/200: Avg Train Loss: 1.6723, Avg Train Acc: 0.8401 (Best: 0.8427)
Epoch 7/200: Avg Val Loss: 1.7037, Avg Val Acc: 0.8511 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 8/200: Avg Train Loss: 1.6714, Avg Train Acc: 0.8319 (Best: 0.8427)
Epoch 8/200: Avg Val Loss: 1.6848, Avg Val Acc: 0.8710 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 9/200: Avg Train Loss: 1.6605, Avg Train Acc: 0.8757 (Best)
Epoch 9/200: Avg Val Loss: 1.6855, Avg Val Acc: 0.8796 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 10/200: Avg Train Loss: 1.6630, Avg Train Acc: 0.8697 (Best: 0.8757)
Epoch 10/200: Avg Val Loss: 1.6661, Avg Val Acc: 0.8647 (Best: 0.8796)
Current learning rate: [0.001]
Patience: 1/20
Epoch 11/200: Avg Train Loss: 1.6636, Avg Train Acc: 0.8579 (Best: 0.8757)
Epoch 11/200: Avg Val Loss: 1.6687, Avg Val Acc: 0.8923 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 12/200: Avg Train Loss: 1.6621, Avg Train Acc: 0.8695 (Best: 0.8757)
Epoch 12/200: Avg Val Loss: 1.6729, Avg Val Acc: 0.8671 (Best: 0.8923)
Current learning rate: [0.001]
Patience: 1/20
Epoch 13/200: Avg Train Loss: 1.6624, Avg Train Acc: 0.8656 (Best: 0.8757)
Epoch 13/200: Avg Val Loss: 1.6711, Avg Val Acc: 0.8753 (Best: 0.8923)
Current learning rate: [0.001]
Patience: 2/20
Epoch 14/200: Avg Train Loss: 1.6630, Avg Train Acc: 0.8699 (Best: 0.8757)
Epoch 14/200: Avg Val Loss: 1.6805, Avg Val Acc: 0.8663 (Best: 0.8923)
Current learning rate: [0.001]
Patience: 3/20
Epoch 15/200: Avg Train Loss: 1.6636, Avg Train Acc: 0.8663 (Best: 0.8757)
Epoch 15/200: Avg Val Loss: 1.6685, Avg Val Acc: 0.8709 (Best: 0.8923)
Current learning rate: [0.001]
Patience: 4/20
Epoch 16/200: Avg Train Loss: 1.6641, Avg Train Acc: 0.8585 (Best: 0.8757)
Epoch 16/200: Avg Val Loss: 1.6714, Avg Val Acc: 0.8725 (Best: 0.8923)
Current learning rate: [0.001]
Patience: 5/20
Epoch 17/200: Avg Train Loss: 1.6626, Avg Train Acc: 0.8599 (Best: 0.8757)
Epoch 17/200: Avg Val Loss: 1.6684, Avg Val Acc: 0.8587 (Best: 0.8923)
Current learning rate: [0.001]
Patience: 6/20
Epoch 18/200: Avg Train Loss: 1.6609, Avg Train Acc: 0.8744 (Best: 0.8757)
Epoch 18/200: Avg Val Loss: 1.6605, Avg Val Acc: 0.8961 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 19/200: Avg Train Loss: 1.6643, Avg Train Acc: 0.8662 (Best: 0.8757)
Epoch 19/200: Avg Val Loss: 1.6907, Avg Val Acc: 0.8692 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 1/20
Epoch 20/200: Avg Train Loss: 1.6600, Avg Train Acc: 0.8733 (Best: 0.8757)
Epoch 20/200: Avg Val Loss: 1.6566, Avg Val Acc: 0.8843 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 2/20
Epoch 21/200: Avg Train Loss: 1.6644, Avg Train Acc: 0.8584 (Best: 0.8757)
Epoch 21/200: Avg Val Loss: 1.6624, Avg Val Acc: 0.8814 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 3/20
Epoch 22/200: Avg Train Loss: 1.6616, Avg Train Acc: 0.8685 (Best: 0.8757)
Epoch 22/200: Avg Val Loss: 1.6568, Avg Val Acc: 0.8849 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 4/20
Epoch 23/200: Avg Train Loss: 1.6621, Avg Train Acc: 0.8627 (Best: 0.8757)
Epoch 23/200: Avg Val Loss: 1.6528, Avg Val Acc: 0.8823 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 5/20
Epoch 24/200: Avg Train Loss: 1.6617, Avg Train Acc: 0.8635 (Best: 0.8757)
Epoch 24/200: Avg Val Loss: 1.6569, Avg Val Acc: 0.8837 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 6/20
Epoch 25/200: Avg Train Loss: 1.6595, Avg Train Acc: 0.8686 (Best: 0.8757)
Epoch 25/200: Avg Val Loss: 1.6766, Avg Val Acc: 0.8562 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 7/20
Epoch 26/200: Avg Train Loss: 1.6603, Avg Train Acc: 0.8657 (Best: 0.8757)
Epoch 26/200: Avg Val Loss: 1.6587, Avg Val Acc: 0.8839 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 8/20
Epoch 27/200: Avg Train Loss: 1.6554, Avg Train Acc: 0.8730 (Best: 0.8757)
Epoch 27/200: Avg Val Loss: 1.6735, Avg Val Acc: 0.8718 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 9/20
Epoch 28/200: Avg Train Loss: 1.6630, Avg Train Acc: 0.8575 (Best: 0.8757)
Epoch 28/200: Avg Val Loss: 1.6590, Avg Val Acc: 0.8785 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 10/20
Epoch 29/200: Avg Train Loss: 1.6601, Avg Train Acc: 0.8664 (Best: 0.8757)
Epoch 29/200: Avg Val Loss: 1.6629, Avg Val Acc: 0.8763 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 11/20
Epoch 30/200: Avg Train Loss: 1.6597, Avg Train Acc: 0.8715 (Best: 0.8757)
Epoch 30/200: Avg Val Loss: 1.6551, Avg Val Acc: 0.8925 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 12/20
Epoch 31/200: Avg Train Loss: 1.6581, Avg Train Acc: 0.8725 (Best: 0.8757)
Epoch 31/200: Avg Val Loss: 1.6637, Avg Val Acc: 0.8730 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 13/20
Epoch 32/200: Avg Train Loss: 1.6582, Avg Train Acc: 0.8806 (Best)
Epoch 32/200: Avg Val Loss: 1.6649, Avg Val Acc: 0.8688 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 14/20
Epoch 33/200: Avg Train Loss: 1.6588, Avg Train Acc: 0.8735 (Best: 0.8806)
Epoch 33/200: Avg Val Loss: 1.6511, Avg Val Acc: 0.8921 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 15/20
Epoch 34/200: Avg Train Loss: 1.6576, Avg Train Acc: 0.8665 (Best: 0.8806)
Epoch 34/200: Avg Val Loss: 1.6533, Avg Val Acc: 0.8791 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 16/20
Epoch 35/200: Avg Train Loss: 1.6552, Avg Train Acc: 0.8865 (Best)
Epoch 35/200: Avg Val Loss: 1.6578, Avg Val Acc: 0.8845 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 17/20
Epoch 36/200: Avg Train Loss: 1.6560, Avg Train Acc: 0.8734 (Best: 0.8865)
Epoch 36/200: Avg Val Loss: 1.6584, Avg Val Acc: 0.8945 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 18/20
Epoch 37/200: Avg Train Loss: 1.6574, Avg Train Acc: 0.8680 (Best: 0.8865)
Epoch 37/200: Avg Val Loss: 1.6621, Avg Val Acc: 0.8767 (Best: 0.8961)
Current learning rate: [0.001]
Patience: 19/20
Epoch 38/200: Avg Train Loss: 1.6562, Avg Train Acc: 0.8731 (Best: 0.8865)
Epoch 38/200: Avg Val Loss: 1.6625, Avg Val Acc: 0.8694 (Best: 0.8961)
Current learning rate: [0.001]
Early stopping in epoch 38
Finish training
