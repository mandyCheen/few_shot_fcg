Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.1700, Avg Train Acc: 0.7855 (Best)
Epoch 1/200: Avg Val Loss: 1.2043, Avg Val Acc: 0.7328 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.1380, Avg Train Acc: 0.8436 (Best)
Epoch 2/200: Avg Val Loss: 1.2957, Avg Val Acc: 0.7966 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.1236, Avg Train Acc: 0.8756 (Best)
Epoch 3/200: Avg Val Loss: 1.2735, Avg Val Acc: 0.8439 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 4/200: Avg Train Loss: 1.1268, Avg Train Acc: 0.8659 (Best: 0.8756)
Epoch 4/200: Avg Val Loss: 1.1446, Avg Val Acc: 0.8533 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 5/200: Avg Train Loss: 1.1162, Avg Train Acc: 0.8880 (Best)
Epoch 5/200: Avg Val Loss: 1.3609, Avg Val Acc: 0.8157 (Best: 0.8533)
Current learning rate: [0.001]
Patience: 1/20
Epoch 6/200: Avg Train Loss: 1.1134, Avg Train Acc: 0.8962 (Best)
Epoch 6/200: Avg Val Loss: 1.1195, Avg Val Acc: 0.9214 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 7/200: Avg Train Loss: 1.1080, Avg Train Acc: 0.8951 (Best: 0.8962)
Epoch 7/200: Avg Val Loss: 1.2234, Avg Val Acc: 0.9113 (Best: 0.9214)
Current learning rate: [0.001]
Patience: 1/20
Epoch 8/200: Avg Train Loss: 1.1071, Avg Train Acc: 0.8964 (Best)
Epoch 8/200: Avg Val Loss: 1.1448, Avg Val Acc: 0.9291 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 9/200: Avg Train Loss: 1.1009, Avg Train Acc: 0.9087 (Best)
Epoch 9/200: Avg Val Loss: 1.2605, Avg Val Acc: 0.8755 (Best: 0.9291)
Current learning rate: [0.001]
Patience: 1/20
Epoch 10/200: Avg Train Loss: 1.1060, Avg Train Acc: 0.9051 (Best: 0.9087)
Epoch 10/200: Avg Val Loss: 1.1563, Avg Val Acc: 0.9115 (Best: 0.9291)
Current learning rate: [0.001]
Patience: 2/20
Epoch 11/200: Avg Train Loss: 1.1066, Avg Train Acc: 0.9024 (Best: 0.9087)
Epoch 11/200: Avg Val Loss: 1.2449, Avg Val Acc: 0.8940 (Best: 0.9291)
Current learning rate: [0.001]
Patience: 3/20
Epoch 12/200: Avg Train Loss: 1.0985, Avg Train Acc: 0.9067 (Best: 0.9087)
Epoch 12/200: Avg Val Loss: 1.1606, Avg Val Acc: 0.9350 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 13/200: Avg Train Loss: 1.0973, Avg Train Acc: 0.9009 (Best: 0.9087)
Epoch 13/200: Avg Val Loss: 1.2157, Avg Val Acc: 0.8809 (Best: 0.9350)
Current learning rate: [0.001]
Patience: 1/20
Epoch 14/200: Avg Train Loss: 1.1038, Avg Train Acc: 0.9062 (Best: 0.9087)
Epoch 14/200: Avg Val Loss: 1.2428, Avg Val Acc: 0.8915 (Best: 0.9350)
Current learning rate: [0.001]
Patience: 2/20
Epoch 15/200: Avg Train Loss: 1.0996, Avg Train Acc: 0.9071 (Best: 0.9087)
Epoch 15/200: Avg Val Loss: 1.1607, Avg Val Acc: 0.9262 (Best: 0.9350)
Current learning rate: [0.001]
Patience: 3/20
Epoch 16/200: Avg Train Loss: 1.1056, Avg Train Acc: 0.8997 (Best: 0.9087)
Epoch 16/200: Avg Val Loss: 1.2454, Avg Val Acc: 0.9153 (Best: 0.9350)
Current learning rate: [0.001]
Patience: 4/20
Epoch 17/200: Avg Train Loss: 1.1004, Avg Train Acc: 0.9034 (Best: 0.9087)
Epoch 17/200: Avg Val Loss: 1.1510, Avg Val Acc: 0.9038 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 5/20
Epoch 18/200: Avg Train Loss: 1.0985, Avg Train Acc: 0.9014 (Best: 0.9087)
Epoch 18/200: Avg Val Loss: 1.1746, Avg Val Acc: 0.9073 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 6/20
Epoch 19/200: Avg Train Loss: 1.0981, Avg Train Acc: 0.9079 (Best: 0.9087)
Epoch 19/200: Avg Val Loss: 1.1645, Avg Val Acc: 0.9161 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 7/20
Epoch 20/200: Avg Train Loss: 1.0967, Avg Train Acc: 0.9134 (Best)
Epoch 20/200: Avg Val Loss: 1.2049, Avg Val Acc: 0.9024 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 8/20
Epoch 21/200: Avg Train Loss: 1.0919, Avg Train Acc: 0.9173 (Best)
Epoch 21/200: Avg Val Loss: 1.2327, Avg Val Acc: 0.8740 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 9/20
Epoch 22/200: Avg Train Loss: 1.0937, Avg Train Acc: 0.9073 (Best: 0.9173)
Epoch 22/200: Avg Val Loss: 1.2337, Avg Val Acc: 0.8815 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 10/20
Epoch 23/200: Avg Train Loss: 1.0951, Avg Train Acc: 0.9149 (Best: 0.9173)
Epoch 23/200: Avg Val Loss: 1.2235, Avg Val Acc: 0.8790 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 11/20
Epoch 24/200: Avg Train Loss: 1.0940, Avg Train Acc: 0.9133 (Best: 0.9173)
Epoch 24/200: Avg Val Loss: 1.2227, Avg Val Acc: 0.8781 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 25/200: Avg Train Loss: 1.0925, Avg Train Acc: 0.9138 (Best: 0.9173)
Epoch 25/200: Avg Val Loss: 1.2374, Avg Val Acc: 0.9019 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 26/200: Avg Train Loss: 1.0992, Avg Train Acc: 0.9061 (Best: 0.9173)
Epoch 26/200: Avg Val Loss: 1.1639, Avg Val Acc: 0.9117 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 14/20
Epoch 27/200: Avg Train Loss: 1.0911, Avg Train Acc: 0.9144 (Best: 0.9173)
Epoch 27/200: Avg Val Loss: 1.1985, Avg Val Acc: 0.8780 (Best: 0.9350)
Current learning rate: [0.0005]
Patience: 15/20
Epoch 28/200: Avg Train Loss: 1.0935, Avg Train Acc: 0.9077 (Best: 0.9173)
Epoch 28/200: Avg Val Loss: 1.1957, Avg Val Acc: 0.8899 (Best: 0.9350)
Current learning rate: [0.00025]
Patience: 16/20
Epoch 29/200: Avg Train Loss: 1.0933, Avg Train Acc: 0.9104 (Best: 0.9173)
Epoch 29/200: Avg Val Loss: 1.2069, Avg Val Acc: 0.8588 (Best: 0.9350)
Current learning rate: [0.00025]
Patience: 17/20
Epoch 30/200: Avg Train Loss: 1.0930, Avg Train Acc: 0.9117 (Best: 0.9173)
Epoch 30/200: Avg Val Loss: 1.1898, Avg Val Acc: 0.9059 (Best: 0.9350)
Current learning rate: [0.00025]
Patience: 18/20
Epoch 31/200: Avg Train Loss: 1.0848, Avg Train Acc: 0.9216 (Best)
Epoch 31/200: Avg Val Loss: 1.2164, Avg Val Acc: 0.8960 (Best: 0.9350)
Current learning rate: [0.00025]
Patience: 19/20
Epoch 32/200: Avg Train Loss: 1.0957, Avg Train Acc: 0.9071 (Best: 0.9216)
Epoch 32/200: Avg Val Loss: 1.2390, Avg Val Acc: 0.8717 (Best: 0.9350)
Current learning rate: [0.00025]
Early stopping in epoch 32
Finish training
