Device: cuda:0
Model: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Loss function: LabelPropagation(
  (encoder): GINLayer(
    (gin_convs): ModuleList(
      (0-2): 3 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
    (norms): ModuleList(
      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlps): ModuleList(
      (0-2): 3 x Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (relation): GraphRelationNetwork(
    (block): GINLayer(
      (gin_convs): ModuleList(
        (0): GINConv(nn=Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        ))
        (1): GINConv(nn=Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        ))
      )
      (norms): ModuleList(
        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (mlps): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=64, bias=True)
        )
        (1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Linear(in_features=64, out_features=32, bias=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
      (2): Linear(in_features=16, out_features=1, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Start training...
Epoch 1/200: Avg Train Loss: 1.6964, Avg Train Acc: 0.8197 (Best)
Epoch 1/200: Avg Val Loss: 1.7635, Avg Val Acc: 0.6690 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 2/200: Avg Train Loss: 1.6766, Avg Train Acc: 0.8449 (Best)
Epoch 2/200: Avg Val Loss: 1.7573, Avg Val Acc: 0.7309 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 3/200: Avg Train Loss: 1.6725, Avg Train Acc: 0.8577 (Best)
Epoch 3/200: Avg Val Loss: 1.7615, Avg Val Acc: 0.6983 (Best: 0.7309)
Current learning rate: [0.001]
Patience: 1/20
Epoch 4/200: Avg Train Loss: 1.6654, Avg Train Acc: 0.8612 (Best)
Epoch 4/200: Avg Val Loss: 1.7144, Avg Val Acc: 0.8612 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 5/200: Avg Train Loss: 1.6649, Avg Train Acc: 0.8592 (Best: 0.8612)
Epoch 5/200: Avg Val Loss: 1.7421, Avg Val Acc: 0.7905 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 1/20
Epoch 6/200: Avg Train Loss: 1.6625, Avg Train Acc: 0.8701 (Best)
Epoch 6/200: Avg Val Loss: 1.7007, Avg Val Acc: 0.8403 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 2/20
Epoch 7/200: Avg Train Loss: 1.6636, Avg Train Acc: 0.8701 (Best: 0.8701)
Epoch 7/200: Avg Val Loss: 1.7628, Avg Val Acc: 0.7865 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 3/20
Epoch 8/200: Avg Train Loss: 1.6640, Avg Train Acc: 0.8685 (Best: 0.8701)
Epoch 8/200: Avg Val Loss: 1.7409, Avg Val Acc: 0.8081 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 4/20
Epoch 9/200: Avg Train Loss: 1.6607, Avg Train Acc: 0.8765 (Best)
Epoch 9/200: Avg Val Loss: 1.7293, Avg Val Acc: 0.8515 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 5/20
Epoch 10/200: Avg Train Loss: 1.6607, Avg Train Acc: 0.8763 (Best: 0.8765)
Epoch 10/200: Avg Val Loss: 1.7534, Avg Val Acc: 0.8198 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 6/20
Epoch 11/200: Avg Train Loss: 1.6592, Avg Train Acc: 0.8852 (Best)
Epoch 11/200: Avg Val Loss: 1.7301, Avg Val Acc: 0.8337 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 7/20
Epoch 12/200: Avg Train Loss: 1.6608, Avg Train Acc: 0.8758 (Best: 0.8852)
Epoch 12/200: Avg Val Loss: 1.7467, Avg Val Acc: 0.8169 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 8/20
Epoch 13/200: Avg Train Loss: 1.6546, Avg Train Acc: 0.8873 (Best)
Epoch 13/200: Avg Val Loss: 1.7761, Avg Val Acc: 0.7929 (Best: 0.8612)
Current learning rate: [0.001]
Patience: 9/20
Epoch 14/200: Avg Train Loss: 1.6579, Avg Train Acc: 0.8829 (Best: 0.8873)
Epoch 14/200: Avg Val Loss: 1.7298, Avg Val Acc: 0.8671 (Best)
Current learning rate: [0.001]
Patience: 0/20
Epoch 15/200: Avg Train Loss: 1.6618, Avg Train Acc: 0.8754 (Best: 0.8873)
Epoch 15/200: Avg Val Loss: 1.7115, Avg Val Acc: 0.8574 (Best: 0.8671)
Current learning rate: [0.001]
Patience: 1/20
Epoch 16/200: Avg Train Loss: 1.6566, Avg Train Acc: 0.8843 (Best: 0.8873)
Epoch 16/200: Avg Val Loss: 1.7491, Avg Val Acc: 0.8165 (Best: 0.8671)
Current learning rate: [0.001]
Patience: 2/20
Epoch 17/200: Avg Train Loss: 1.6559, Avg Train Acc: 0.8845 (Best: 0.8873)
Epoch 17/200: Avg Val Loss: 1.7289, Avg Val Acc: 0.8577 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 3/20
Epoch 18/200: Avg Train Loss: 1.6531, Avg Train Acc: 0.8959 (Best)
Epoch 18/200: Avg Val Loss: 1.7279, Avg Val Acc: 0.8382 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 4/20
Epoch 19/200: Avg Train Loss: 1.6523, Avg Train Acc: 0.8827 (Best: 0.8959)
Epoch 19/200: Avg Val Loss: 1.7274, Avg Val Acc: 0.8513 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 5/20
Epoch 20/200: Avg Train Loss: 1.6535, Avg Train Acc: 0.8897 (Best: 0.8959)
Epoch 20/200: Avg Val Loss: 1.7839, Avg Val Acc: 0.8069 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 6/20
Epoch 21/200: Avg Train Loss: 1.6575, Avg Train Acc: 0.8770 (Best: 0.8959)
Epoch 21/200: Avg Val Loss: 1.7297, Avg Val Acc: 0.8501 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 7/20
Epoch 22/200: Avg Train Loss: 1.6550, Avg Train Acc: 0.8812 (Best: 0.8959)
Epoch 22/200: Avg Val Loss: 1.7462, Avg Val Acc: 0.8456 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 8/20
Epoch 23/200: Avg Train Loss: 1.6530, Avg Train Acc: 0.8835 (Best: 0.8959)
Epoch 23/200: Avg Val Loss: 1.7302, Avg Val Acc: 0.8441 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 9/20
Epoch 24/200: Avg Train Loss: 1.6543, Avg Train Acc: 0.8831 (Best: 0.8959)
Epoch 24/200: Avg Val Loss: 1.7309, Avg Val Acc: 0.8345 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 10/20
Epoch 25/200: Avg Train Loss: 1.6529, Avg Train Acc: 0.8936 (Best: 0.8959)
Epoch 25/200: Avg Val Loss: 1.7556, Avg Val Acc: 0.7923 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 11/20
Epoch 26/200: Avg Train Loss: 1.6545, Avg Train Acc: 0.8869 (Best: 0.8959)
Epoch 26/200: Avg Val Loss: 1.7477, Avg Val Acc: 0.8199 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 12/20
Epoch 27/200: Avg Train Loss: 1.6547, Avg Train Acc: 0.8868 (Best: 0.8959)
Epoch 27/200: Avg Val Loss: 1.7432, Avg Val Acc: 0.8174 (Best: 0.8671)
Current learning rate: [0.0005]
Patience: 13/20
Epoch 28/200: Avg Train Loss: 1.6523, Avg Train Acc: 0.8920 (Best: 0.8959)
Epoch 28/200: Avg Val Loss: 1.7311, Avg Val Acc: 0.8385 (Best: 0.8671)
Current learning rate: [0.00025]
Patience: 14/20
Epoch 29/200: Avg Train Loss: 1.6489, Avg Train Acc: 0.8977 (Best)
Epoch 29/200: Avg Val Loss: 1.7525, Avg Val Acc: 0.8241 (Best: 0.8671)
Current learning rate: [0.00025]
Patience: 15/20
Epoch 30/200: Avg Train Loss: 1.6508, Avg Train Acc: 0.8892 (Best: 0.8977)
Epoch 30/200: Avg Val Loss: 1.7431, Avg Val Acc: 0.8295 (Best: 0.8671)
Current learning rate: [0.00025]
Patience: 16/20
Epoch 31/200: Avg Train Loss: 1.6489, Avg Train Acc: 0.8933 (Best: 0.8977)
Epoch 31/200: Avg Val Loss: 1.7653, Avg Val Acc: 0.7965 (Best: 0.8671)
Current learning rate: [0.00025]
Patience: 17/20
Epoch 32/200: Avg Train Loss: 1.6514, Avg Train Acc: 0.8912 (Best: 0.8977)
Epoch 32/200: Avg Val Loss: 1.7414, Avg Val Acc: 0.8380 (Best: 0.8671)
Current learning rate: [0.00025]
Patience: 18/20
Epoch 33/200: Avg Train Loss: 1.6528, Avg Train Acc: 0.8834 (Best: 0.8977)
Epoch 33/200: Avg Val Loss: 1.7341, Avg Val Acc: 0.8376 (Best: 0.8671)
Current learning rate: [0.00025]
Patience: 19/20
Epoch 34/200: Avg Train Loss: 1.6520, Avg Train Acc: 0.8877 (Best: 0.8977)
Epoch 34/200: Avg Val Loss: 1.7781, Avg Val Acc: 0.7771 (Best: 0.8671)
Current learning rate: [0.00025]
Early stopping in epoch 34
Finish training
