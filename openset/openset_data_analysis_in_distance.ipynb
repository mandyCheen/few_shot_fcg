{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys  \n",
    "sys.path.insert(1, '/home/manying/Projects/fcgFewShot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "options = load_config(\"../config/config_label_prop_openset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Loading openset data...\n",
      "Openset data shape: (171, 16)\n"
     ]
    }
   ],
   "source": [
    "from loadDataset import LoadDataset\n",
    "from fcgVectorize import FCGVectorize\n",
    "from trainModule import TrainModule\n",
    "from trainModule import TestModule\n",
    "import os\n",
    "\n",
    "dataset = LoadDataset(options, pretrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model exist, load word2vec model...\n",
      "Start to get node embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:00<00:00, 25147.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish getting node embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = FCGVectorize(options, dataset)\n",
    "vectorizer.node_embedding(dataset.opensetData, openset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the training module...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec...\n",
      "Loading training data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/trainData.pkl...\n",
      "Loading validation data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/valData.pkl...\n",
      "Device: cuda:0\n",
      "Model: LabelPropagation(\n",
      "  (encoder): GraphSAGELayer(\n",
      "    (sage_convs): ModuleList(\n",
      "      (0-2): 3 x SAGEConv(128, 128, aggr=mean)\n",
      "    )\n",
      "    (norms): ModuleList(\n",
      "      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (relation): GraphRelationNetwork(\n",
      "    (sage): GraphSAGELayer(\n",
      "      (sage_convs): ModuleList(\n",
      "        (0): SAGEConv(128, 64, aggr=mean)\n",
      "        (1): SAGEConv(64, 32, aggr=mean)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Loss function: LabelPropagation(\n",
      "  (encoder): GraphSAGELayer(\n",
      "    (sage_convs): ModuleList(\n",
      "      (0-2): 3 x SAGEConv(128, 128, aggr=mean)\n",
      "    )\n",
      "    (norms): ModuleList(\n",
      "      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (relation): GraphRelationNetwork(\n",
      "    (sage): GraphSAGELayer(\n",
      "      (sage_convs): ModuleList(\n",
      "        (0): SAGEConv(128, 64, aggr=mean)\n",
      "        (1): SAGEConv(64, 32, aggr=mean)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Finish setting up the training module\n"
     ]
    }
   ],
   "source": [
    "trainModule = TrainModule(options, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the testing module...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec...\n",
      "Loading testing data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/testData.pkl...\n",
      "Loading openset data...\n",
      "Loading openset data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/opensetData_random_0.1.pkl...\n",
      "Finish setting up the testing module\n",
      "Model loaded from /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_888_baseline/10way_5shot_LabelPropagation_alpha0.7_k20_20250316_133650/epoch_42_0.8847333538532257_best.pth\n",
      "Class 0: Average distance = 73166.0078125\n",
      "Class 1: Average distance = 80139.015625\n",
      "Class 2: Average distance = 16068.0537109375\n",
      "Class 3: Average distance = 74.07701873779297\n",
      "Class 4: Average distance = 102308.5\n",
      "Class 5: Average distance = 28627.884765625\n",
      "Class 6: Average distance = 12941.2236328125\n",
      "Class 7: Average distance = 1152841344.0\n",
      "Class 8: Average distance = 158.2317657470703\n",
      "Class 9: Average distance = 6932.7041015625\n",
      "Average distance:  tensor(1.1532e+08, device='cuda:0')\n",
      "torch.Size([20, 50])\n",
      "Accuracy:  0.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "testConfigPath = \"/home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_888_baseline/10way_5shot_LabelPropagation_alpha0.7_k20_20250316_133650/config.json\"\n",
    "\n",
    "testModule = TestModule(testConfigPath, dataset, options)\n",
    "\n",
    "testLoader = testModule.testLoader\n",
    "opensetLoader = testModule.opensetLoader\n",
    "\n",
    "accuracy_query = []\n",
    "accuracy_openset = []\n",
    "\n",
    "testModule.load_best_model()\n",
    "for testData in testLoader:\n",
    "    testModule.model.eval()\n",
    "    testData = testData.to(testModule.device)\n",
    "    with torch.no_grad():\n",
    "        testDataEncoded = testModule.model.get_encoded_data(testData)\n",
    "        avg_dist = testModule.model.get_avg_distance_between_support(testDataEncoded, testData.y)\n",
    "        print(\"Average distance: \", avg_dist)\n",
    "        for opensetData in opensetLoader:\n",
    "            predicts = []\n",
    "            opensetData = opensetData.to(testModule.device)\n",
    "            testModule.model.eval()\n",
    "            with torch.no_grad():\n",
    "                testDataEncoded = testModule.model.get_encoded_data(testData)\n",
    "                opensetDataEncoded = testModule.model.get_encoded_data(opensetData)\n",
    "                dists = testModule.model.get_openset_distance_between_support(testDataEncoded, testData.y, opensetData)  \n",
    "                for i in range(dists.shape[0]):\n",
    "                    min_dist = torch.min(dists[i])\n",
    "                    if min_dist <= avg_dist:\n",
    "                        predicts.append(0) # not openset\n",
    "                    else:\n",
    "                        predicts.append(1) # openset\n",
    "                print(dists.shape)\n",
    "            # count the number of openset samples\n",
    "            num_openset = sum(predicts)\n",
    "            print(\"Accuracy: \", (num_openset) / len(predicts))\n",
    "            accuracy_openset.append((num_openset) / len(predicts))\n",
    "            break\n",
    "        testDataEncoded = testModule.model.get_encoded_data(testData)\n",
    "        query_dist = testModule.model.get_query_distance_between_support(testDataEncoded, testData.y)\n",
    "        predicts = []\n",
    "        for i in range(query_dist.shape[0]):\n",
    "            min_dist = torch.min(query_dist[i])\n",
    "            if min_dist >= avg_dist:\n",
    "                predicts.append(0) # not query\n",
    "            else:   \n",
    "                predicts.append(1)\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "options = load_config(\"../config/config_nn_openset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Loading openset data...\n",
      "Openset data shape: (171, 16)\n"
     ]
    }
   ],
   "source": [
    "from loadDataset import LoadDataset\n",
    "from fcgVectorize import FCGVectorize\n",
    "from trainModule import TrainModule\n",
    "from trainModule import TestModule\n",
    "import os\n",
    "\n",
    "dataset = LoadDataset(options, pretrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the training module...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec...\n",
      "Loading training data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/trainData.pkl...\n",
      "Loading validation data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/valData.pkl...\n",
      "Device: cuda:0\n",
      "Model: GraphSAGE(\n",
      "  (sage_convs): ModuleList(\n",
      "    (0-1): 2 x SAGEConv(128, 128, aggr=mean)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-1): 2 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (output_proj): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n",
      "Loss function: <loss.NnLoss object at 0x7f559e819f10>\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Finish setting up the training module\n"
     ]
    }
   ],
   "source": [
    "trainModule = TrainModule(options, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the testing module...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec...\n",
      "Loading testing data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/testData.pkl...\n",
      "Loading openset data...\n",
      "Loading openset data...\n",
      "Loading data from ../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/opensetData_random_0.1.pkl...\n",
      "Finish setting up the testing module\n",
      "Model loaded from /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_888_baseline/10way_5shot_NnNet_with_pretrain_20250108_221055/epoch_25_best.pth\n",
      "Class 0: Average distance = 28.6367130279541\n",
      "Class 1: Average distance = 4.132623195648193\n",
      "Class 2: Average distance = 0.6481151580810547\n",
      "Class 3: Average distance = 6.461498088021706e-15\n",
      "Class 4: Average distance = 2.3675599098205566\n",
      "Class 5: Average distance = 2.337858200073242\n",
      "Class 6: Average distance = 0.30937156081199646\n",
      "Class 7: Average distance = 51.00477981567383\n",
      "Class 8: Average distance = 3.094170021112133e-14\n",
      "Class 9: Average distance = 0.14341990649700165\n",
      "Lower bound: -5.074766159057617, Upper bound: 8.951031684875488\n",
      "Average distance:  tensor(1.2424, device='cuda:0')\n",
      "labelDictOpenset:  {'3proxy': 0, 'acpi': 1, 'adduser': 2, 'adrastea': 3, 'aircrack': 4, 'azeela': 5, 'blackcat': 6, 'blueshell': 7, 'bluez': 8, 'bruteratel': 9, 'cobaltstrike': 10, 'conti': 11, 'cornelgen': 12, 'crumbs': 13, 'cryptonote': 14, 'deimos': 15, 'derusbi': 16, 'detected': 17, 'diamorphinerootkit': 18, 'disco': 19, 'discord': 20, 'doki': 21, 'earthworm': 22, 'ech0raix': 23, 'erebus': 24, 'esxiargs': 25, 'ettercap': 26, 'fiforeg': 27, 'flurry': 28, 'foda': 29, 'fokirtor': 30, 'fritzfrog': 31, 'fscan': 32, 'gminer': 33, 'godlua': 34, 'goscanssh': 35, 'gsnetcat': 36, 'gustuff': 37, 'hellobot': 38, 'hider': 39, 'hydra': 40, 'icmpdoor': 41, 'impacket': 42, 'iotroop': 43, 'keyplug': 44, 'kobalos': 45, 'lady': 46, 'lamer': 47, 'lazer': 48, 'libprocesshider': 49, 'ligolo': 50, 'lilock': 51, 'loerbas': 52, 'logkeys': 53, 'luckymouse': 54, 'lxbot': 55, 'manjusaka': 56, 'marte': 57, 'mccrash': 58, 'melofee': 59, 'metasploit': 60, 'mettle': 61, 'mydoom': 62, 'nukespeed': 63, 'openssl': 64, 'orbit': 65, 'p2pinfect': 66, 'patacore': 67, 'pgminer': 68, 'ptrace': 69, 'pyfatget': 70, 'qsnatch': 71, 'quantum': 72, 'randkit': 73, 'redxor': 74, 'reverseshell': 75, 'reversessh': 76, 'rotajakiro': 77, 'royal': 78, 'ryokoc': 79, 'sagent': 80, 'shbin': 81, 'snessik': 82, 'spectre': 83, 'spyc': 84, 'stealthworker': 85, 'stowaway': 86, 'subversive': 87, 'sutekh': 88, 'suterusu': 89, 'symbiote': 90, 'threeproxy': 91, 'tmate': 92, 'torii': 93, 'tpyc': 94, 'umbreon': 95, 'veil': 96, 'venom': 97, 'wellmess': 98, 'xagent': 99, 'xbash': 100, 'xmrminer': 101, 'xmrstak': 102, 'xpmmap': 103, 'zapchast': 104, 'zenbleed': 105, 'zkarletflash': 106, 'zpevdo': 107}\n",
      "min_dist:  tensor(0.8837, device='cuda:0') Label:  tensor(88, device='cuda:0')\n",
      "min_dist:  tensor(8.8877, device='cuda:0') Label:  tensor(28, device='cuda:0')\n",
      "min_dist:  tensor(189.6567, device='cuda:0') Label:  tensor(106, device='cuda:0')\n",
      "min_dist:  tensor(2.9420, device='cuda:0') Label:  tensor(64, device='cuda:0')\n",
      "min_dist:  tensor(0.6053, device='cuda:0') Label:  tensor(17, device='cuda:0')\n",
      "min_dist:  tensor(7.4909, device='cuda:0') Label:  tensor(6, device='cuda:0')\n",
      "min_dist:  tensor(6.5340, device='cuda:0') Label:  tensor(85, device='cuda:0')\n",
      "min_dist:  tensor(0.6053, device='cuda:0') Label:  tensor(17, device='cuda:0')\n",
      "min_dist:  tensor(2.9844, device='cuda:0') Label:  tensor(11, device='cuda:0')\n",
      "min_dist:  tensor(0.6053, device='cuda:0') Label:  tensor(17, device='cuda:0')\n",
      "min_dist:  tensor(0.7296, device='cuda:0') Label:  tensor(71, device='cuda:0')\n",
      "min_dist:  tensor(4.9090, device='cuda:0') Label:  tensor(77, device='cuda:0')\n",
      "min_dist:  tensor(6.5887, device='cuda:0') Label:  tensor(85, device='cuda:0')\n",
      "min_dist:  tensor(1.9462, device='cuda:0') Label:  tensor(22, device='cuda:0')\n",
      "min_dist:  tensor(24.7301, device='cuda:0') Label:  tensor(66, device='cuda:0')\n",
      "min_dist:  tensor(0.1614, device='cuda:0') Label:  tensor(95, device='cuda:0')\n",
      "min_dist:  tensor(5.8996, device='cuda:0') Label:  tensor(35, device='cuda:0')\n",
      "min_dist:  tensor(3.0083, device='cuda:0') Label:  tensor(105, device='cuda:0')\n",
      "min_dist:  tensor(3.6734, device='cuda:0') Label:  tensor(3, device='cuda:0')\n",
      "min_dist:  tensor(6.1072, device='cuda:0') Label:  tensor(99, device='cuda:0')\n",
      "Accuracy:  0.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "testConfigPath = \"/home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_888_baseline/10way_5shot_NnNet_with_pretrain_20250108_221055/config.json\"\n",
    "\n",
    "testModule = TestModule(testConfigPath, dataset, options)\n",
    "\n",
    "testLoader = testModule.testLoader\n",
    "opensetLoader = testModule.opensetLoader\n",
    "\n",
    "accuracy_query = []\n",
    "accuracy_openset = []\n",
    "\n",
    "testModule.load_best_model()\n",
    "for testData in testLoader:\n",
    "    testModule.model.eval()\n",
    "    testData = testData.to(testModule.device)\n",
    "    with torch.no_grad():\n",
    "        testDataEncoded = testModule.model(testData)\n",
    "        avg_dist = testModule.loss_fn.get_avg_distance_between_support(testDataEncoded, testData.y)\n",
    "        print(\"Average distance: \", avg_dist)\n",
    "        for opensetData in opensetLoader:\n",
    "            predicts = []\n",
    "            opensetData = opensetData.to(testModule.device)\n",
    "            testModule.model.eval()\n",
    "            with torch.no_grad():\n",
    "                testDataEncoded = testModule.model(testData)\n",
    "                opensetDataEncoded = testModule.model(opensetData)\n",
    "                dists = testModule.loss_fn.get_openset_distance_between_support(testDataEncoded, testData.y, opensetDataEncoded)  \n",
    "                labelDictOpenset = {}\n",
    "                with open(\"../embeddings/x86_64_withVal_withPretrain_ghidra_888/word2vec/labelDict_openset_random_0.1.pkl\", \"rb\") as f:\n",
    "                    labelDictOpenset = pickle.load(f)\n",
    "                print(\"labelDictOpenset: \", labelDictOpenset)\n",
    "                for i in range(dists.shape[0]):\n",
    "                    min_dist = torch.min(dists[i])\n",
    "                    print(\"min_dist: \", min_dist, \"Label: \", opensetData.y[i])\n",
    "                    if min_dist <= avg_dist:\n",
    "                        predicts.append(0) # not openset\n",
    "                    else:\n",
    "                        predicts.append(1) # openset\n",
    "            # count the number of openset samples\n",
    "            num_openset = sum(predicts)\n",
    "            print(\"Accuracy: \", (num_openset) / len(predicts))\n",
    "            accuracy_openset.append((num_openset) / len(predicts))\n",
    "            break\n",
    "        testDataEncoded = testModule.model(testData)\n",
    "        query_dist = testModule.loss_fn.get_query_distance_between_support(testDataEncoded, testData.y)\n",
    "        predicts = []\n",
    "        for i in range(query_dist.shape[0]):\n",
    "            min_dist = torch.min(query_dist[i])\n",
    "            if min_dist >= avg_dist:\n",
    "                predicts.append(0) # not query\n",
    "            else:   \n",
    "                predicts.append(1)\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
