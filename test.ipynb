{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "options = load_config(\"./config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (940, 3)\n",
      "train dataset family number: 47\n",
      "test dataset shape: (200, 3)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 3)\n",
      "val dataset family number: 10\n"
     ]
    }
   ],
   "source": [
    "from loadDataset import LoadDataset\n",
    "dataset = LoadDataset(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model exist, load word2vec model...\n",
      "Start to get node embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1340/1340 [00:00<00:00, 27550.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish getting node embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fcgVectorize import FCGVectorize\n",
    "\n",
    "vectorizer = FCGVectorize(options, dataset)\n",
    "# node embedding for raw data\n",
    "vectorizer.node_embedding(dataset.rawDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import TrainModule\n",
    "trainModule = TrainModule(options, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/940 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "nan_to_num(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     fcg \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m fcg\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m---> 18\u001b[0m     fcg\u001b[38;5;241m.\u001b[39mnodes[node][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan_to_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfcg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m torch_data \u001b[38;5;241m=\u001b[39m from_networkx(fcg)\n\u001b[1;32m     20\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(family)\n",
      "\u001b[0;31mTypeError\u001b[0m: nan_to_num(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from sklearn import preprocessing as labelEncoder\n",
    "\n",
    "labels = []\n",
    "graphList = []\n",
    "\n",
    "for index, row in tqdm(trainModule.trainDataset.iterrows(), total=trainModule.trainDataset.shape[0]):\n",
    "    cpu = row[\"CPU\"]\n",
    "    family = row[\"family\"]\n",
    "    fileName = row[\"file_name\"]\n",
    "    filePath = f\"{trainModule.embeddingFolder}/{cpu}/{family}/{fileName}.gpickle\"\n",
    "    with open(filePath, \"rb\") as f:\n",
    "        fcg = pickle.load(f)\n",
    "    for node in fcg.nodes:\n",
    "        fcg.nodes[node][\"x\"] = torch.nan_to_num(fcg.nodes[node][\"x\"], nan=0.0)\n",
    "    torch_data = from_networkx(fcg)\n",
    "    labels.append(family)\n",
    "    graphList.append(torch_data)\n",
    "le = labelEncoder.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_ = le.transform(labels)\n",
    "for i, data in enumerate(graphList):\n",
    "    data.y = torch.tensor(labels_[i])\n",
    "    data.num_nodes = len(data.x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import FcgSampler\n",
    "sampler = FcgSampler(labels_, trainModule.support_shots, trainModule.class_per_iter, trainModule.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "def collate_graphs(batch):\n",
    "    return Batch.from_data_list(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "loader = DataLoader(graphList, batch_sampler=sampler, num_workers=32, collate_fn=collate_graphs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = DataLoader(graphList, batch_size=50, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[100], edge_index=[2, 987371], y=[100], num_nodes=256437, batch=[256437], ptr=[101])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.x shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mgraphList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.x type:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(graphList[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(\"data.x shape:\", graphList[0].x.shape)\n",
    "print(\"data.x type:\", type(graphList[0].x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
