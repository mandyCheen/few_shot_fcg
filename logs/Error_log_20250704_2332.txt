2025-07-05 02:30:06.205188: 10way_10shot CUDA out of memory. Tried to allocate 790.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 462.75 MiB is free. Including non-PyTorch memory, this process has 11.20 GiB memory in use. Of the allocated memory 9.66 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-05 05:44:37.165131: 10way_10shot CUDA out of memory. Tried to allocate 718.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 704.75 MiB is free. Including non-PyTorch memory, this process has 10.96 GiB memory in use. Of the allocated memory 9.84 GiB is allocated by PyTorch, and 839.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-05 07:45:23.319931: 10way_10shot CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 688.75 MiB is free. Including non-PyTorch memory, this process has 10.98 GiB memory in use. Of the allocated memory 9.85 GiB is allocated by PyTorch, and 845.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-05 10:39:53.247676: 10way_10shot CUDA out of memory. Tried to allocate 746.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 318.75 MiB is free. Including non-PyTorch memory, this process has 11.34 GiB memory in use. Of the allocated memory 10.01 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-05 13:09:39.484783: 10way_10shot CUDA out of memory. Tried to allocate 790.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 562.75 MiB is free. Including non-PyTorch memory, this process has 11.10 GiB memory in use. Of the allocated memory 9.56 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
