{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "seeds = [6, 7, 10, 11, 19, 22, 31, 42, 666, 888]\n",
    "splitFilePrefix = '_x86_64_withVal_withPretrain_ghidra_'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Graph2Vec Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WLGraph2Vec:\n",
    "    def __init__(self, num_iterations=3):\n",
    "        \"\"\"\n",
    "        初始化 WL Graph2Vec\n",
    "        \n",
    "        參數:\n",
    "            num_iterations: WL迭代次數\n",
    "        \"\"\"\n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def _wl_iteration(self, G, node_features):\n",
    "        \"\"\"執行一次WL迭代\"\"\"\n",
    "        new_features = {}\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            # 獲取節點當前特徵\n",
    "            current_feature = node_features[node]\n",
    "            \n",
    "            # 收集所有鄰居的特徵\n",
    "            neighbor_features = []\n",
    "            for neighbor in G.neighbors(node):\n",
    "                neighbor_features.append(node_features[neighbor])\n",
    "            \n",
    "            if neighbor_features:\n",
    "                # 計算鄰居特徵的平均值\n",
    "                neighbor_mean = np.mean(neighbor_features, axis=0)\n",
    "                # 組合當前節點特徵和鄰居特徵\n",
    "                new_feature = 0.5 * current_feature + 0.5 * neighbor_mean\n",
    "            else:\n",
    "                new_feature = current_feature\n",
    "                \n",
    "            new_features[node] = new_feature\n",
    "            \n",
    "        return new_features\n",
    "\n",
    "    def transform(self, G):\n",
    "        \"\"\"\n",
    "        使用WL機制將圖轉換為128維向量\n",
    "        \n",
    "        參數:\n",
    "            G: networkx圖物件，節點的'x'屬性包含tensor特徵\n",
    "        返回:\n",
    "            numpy.ndarray: 128維向量\n",
    "        \"\"\"\n",
    "        # 初始化節點特徵\n",
    "        node_features = {}\n",
    "        for node in G.nodes():\n",
    "            if isinstance(G.nodes[node]['x'], torch.Tensor):\n",
    "                node_features[node] = G.nodes[node]['x'].numpy()\n",
    "            else:\n",
    "                node_features[node] = np.array(G.nodes[node]['x'])\n",
    "        \n",
    "        # 儲存每次迭代的圖級別特徵\n",
    "        graph_features = []\n",
    "        \n",
    "        # WL迭代\n",
    "        for _ in range(self.num_iterations):\n",
    "            # 更新節點特徵\n",
    "            node_features = self._wl_iteration(G, node_features)\n",
    "            \n",
    "            # 計算當前迭代的圖級別特徵\n",
    "            current_features = np.array(list(node_features.values()))\n",
    "            graph_features.append(np.mean(current_features, axis=0))\n",
    "            graph_features.append(np.max(current_features, axis=0))\n",
    "            graph_features.append(np.min(current_features, axis=0))\n",
    "        \n",
    "        # 組合所有特徵\n",
    "        combined_features = np.concatenate(graph_features)\n",
    "        \n",
    "        # 如果特徵維度不是128，則需要調整\n",
    "        if len(combined_features) > 128:\n",
    "            # 使用平均池化減少維度\n",
    "            splits = np.array_split(combined_features, 128)\n",
    "            final_vector = np.array([np.mean(split) for split in splits])\n",
    "        elif len(combined_features) < 128:\n",
    "            # 使用線性插值增加維度\n",
    "            original_positions = np.linspace(0, 1, len(combined_features))\n",
    "            new_positions = np.linspace(0, 1, 128)\n",
    "            final_vector = np.interp(new_positions, original_positions, combined_features)\n",
    "        else:\n",
    "            final_vector = combined_features\n",
    "            \n",
    "        # 標準化最終向量\n",
    "        if np.std(final_vector) != 0:\n",
    "            final_vector = (final_vector - np.mean(final_vector)) / np.std(final_vector)\n",
    "        else:\n",
    "            final_vector = final_vector - np.mean(final_vector)\n",
    "\n",
    "        return final_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import from_networkx\n",
    "def load_split_data(seed):\n",
    "    \"\"\"\n",
    "    載入訓練集、驗證集和測試集\n",
    "    \n",
    "    參數:\n",
    "        seed: 隨機種子\n",
    "    返回:\n",
    "        tuple: (訓練集, 驗證集, 測試集)\n",
    "    \"\"\"\n",
    "    path = \"/home/manying/Projects/fcgFewShot/dataset/split\"\n",
    "\n",
    "    train_file = os.path.join(path, 'train'+ splitFilePrefix + str(seed) + '.txt')\n",
    "    val_file = os.path.join(path, 'val'+ splitFilePrefix + str(seed) + '.txt')\n",
    "    test_file = os.path.join(path, 'test'+ splitFilePrefix + str(seed) + '.txt')\n",
    "    \n",
    "\n",
    "    train_data = []\n",
    "    with open(train_file, 'r') as f:\n",
    "        for line in f:\n",
    "            train_data.append(line.strip())\n",
    "    \n",
    "    val_data = []\n",
    "\n",
    "    with open(val_file, 'r') as f:\n",
    "        for line in f:\n",
    "            val_data.append(line.strip())\n",
    "    \n",
    "    test_data = []\n",
    "    with open(test_file, 'r') as f:\n",
    "        for line in f:\n",
    "            test_data.append(line.strip())\n",
    "        \n",
    "    return train_data, val_data, test_data \n",
    "\n",
    "def load_dataset(familyList, seed):\n",
    "    \"\"\"\n",
    "    載入圖數據集\n",
    "    \n",
    "    參數:\n",
    "        familyList: list of str, 指定要載入的家族名稱\n",
    "    返回:\n",
    "        list of networkx.Graph: 圖數據集\n",
    "    \"\"\"\n",
    "    path = f\"/home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_{seed}/word2vec/Advanced Micro Devices X86-64\"\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "    for family in familyList:\n",
    "        graph_folder = os.path.join(path, family)\n",
    "        for graph_file in os.listdir(graph_folder):\n",
    "            if graph_file.endswith('.gpickle'):\n",
    "                graph = load_graph(os.path.join(graph_folder, graph_file))\n",
    "                graphs.append(graph)\n",
    "                labels.append(family)\n",
    "                paths.append(os.path.join(graph_folder, graph_file))\n",
    "    return graphs, labels, paths\n",
    "\n",
    "def load_graph(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        fcg = pickle.load(f)\n",
    "        for node in fcg.nodes:\n",
    "            if len(fcg.nodes[node][\"x\"]) == 0:\n",
    "                fcg.nodes[node][\"x\"] = torch.zeros(128, dtype=torch.float32)\n",
    "            if not isinstance(fcg.nodes[node][\"x\"], torch.Tensor):\n",
    "                fcg.nodes[node][\"x\"] = torch.tensor(fcg.nodes[node][\"x\"], dtype=torch.float32)\n",
    "    return fcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def evaluate_few_shot(test_vectors, test_labels, n_episodes=100, mode=\"Nn\"):\n",
    "    \"\"\"\n",
    "    評估few-shot learning的平均準確率\n",
    "    \n",
    "    參數:\n",
    "        test_vectors: 測試數據向量\n",
    "        test_labels: 測試數據標籤\n",
    "        n_episodes: 評估回合數\n",
    "    \"\"\"\n",
    "    # 整理每個類別的樣本索引\n",
    "    label_to_indices = defaultdict(list)\n",
    "    for idx, label in enumerate(test_labels):\n",
    "        label_to_indices[label].append(idx)\n",
    "    \n",
    "    def run_episode(n_way, n_shot):\n",
    "        # 計算query樣本數量：共20個樣本減去support set的數量\n",
    "        n_query = 20 - n_shot\n",
    "        \n",
    "        # 隨機選擇n_way個類別\n",
    "        selected_classes = random.sample(list(label_to_indices.keys()), n_way)\n",
    "        support_X = []\n",
    "        support_y = []\n",
    "        query_X = []\n",
    "        query_y = []\n",
    "        \n",
    "        # 對每個選中的類別採樣數據\n",
    "        for cls in selected_classes:\n",
    "            cls_indices = label_to_indices[cls]\n",
    "            selected_indices = random.sample(cls_indices, n_shot + n_query)\n",
    "            \n",
    "            # 分割support set和query set\n",
    "            support_indices = selected_indices[:n_shot]\n",
    "            query_indices = selected_indices[n_shot:]\n",
    "            \n",
    "            # 收集數據\n",
    "            support_X.extend([test_vectors[idx] for idx in support_indices])\n",
    "            support_y.extend([cls] * n_shot)\n",
    "            query_X.extend([test_vectors[idx] for idx in query_indices])\n",
    "            query_y.extend([cls] * n_query)\n",
    "        \n",
    "        # 轉換為numpy數組\n",
    "        support_X = np.array(support_X)\n",
    "        support_y = np.array(support_y)\n",
    "        query_X = np.array(query_X)\n",
    "        query_y = np.array(query_y)\n",
    "\n",
    "        if mode == \"Proto\":\n",
    "            # 計算每個類別的原型向量\n",
    "            prototypes = []\n",
    "            for cls in selected_classes:\n",
    "                cls_indices = np.where(support_y == cls)[0]\n",
    "                cls_vectors = support_X[cls_indices]\n",
    "                prototype = np.mean(cls_vectors, axis=0)\n",
    "                prototypes.append(prototype)\n",
    "            prototypes = np.array(prototypes)\n",
    "\n",
    "            # 計算每個query樣本到原型向量的歐幾里得距離\n",
    "            distances = np.linalg.norm(query_X[:, None] - prototypes, axis=2)\n",
    "            predictions = np.argmin(distances, axis=1)\n",
    "            predictions = np.array([selected_classes[pred] for pred in predictions])\n",
    "            \n",
    "        elif mode == \"Nn\":\n",
    "            # 訓練和預測\n",
    "            classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "            classifier.fit(support_X, support_y)\n",
    "            predictions = classifier.predict(query_X)\n",
    "        \n",
    "        # 計算準確率\n",
    "        accuracy = np.mean(predictions == query_y)\n",
    "        confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "        if mode == \"Proto\" and n_way == 10 and n_shot == 5:\n",
    "            ## generate confusion matrix in 10-way 5-shot\n",
    "            for i in range(len(predictions)):\n",
    "                confusion_matrix[query_y[i]][predictions[i]] += 1\n",
    "            confusion_matrix = confusion_matrix / np.sum(confusion_matrix, axis=1)[:, None]\n",
    "\n",
    "        return accuracy, confusion_matrix\n",
    "    \n",
    "    # 評估所有配置\n",
    "    configs = [(5, 5), (10, 5), (5, 10), (10, 10)]\n",
    "    results = {}\n",
    "    \n",
    "    for n_way, n_shot in configs:\n",
    "        # 運行n_episodes次並計算平均準確率\n",
    "        if mode == \"Proto\":\n",
    "            accuracies = []\n",
    "            confusion_matrix = np.zeros((10, 10))\n",
    "            for _ in range(n_episodes):\n",
    "                accuracy, confusion_matrix = run_episode(n_way, n_shot)\n",
    "                accuracies.append(accuracy)\n",
    "                confusion_matrix += confusion_matrix\n",
    "            results[f\"{n_way}-way {n_shot}-shot\"] = np.mean(accuracies), confusion_matrix / n_episodes\n",
    "        elif mode == \"Nn\":\n",
    "            accuracies = [run_episode(n_way, n_shot)[0] for _ in range(n_episodes)]\n",
    "            results[f\"{n_way}-way {n_shot}-shot\"] = np.mean(accuracies)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs to vectors...\n",
      "seed: 7\n",
      "Converting graphs to vectors...\n",
      "seed: 10\n",
      "Converting graphs to vectors...\n",
      "seed: 11\n",
      "Converting graphs to vectors...\n",
      "seed: 19\n",
      "Converting graphs to vectors...\n",
      "seed: 22\n",
      "Converting graphs to vectors...\n",
      "seed: 31\n",
      "Converting graphs to vectors...\n",
      "seed: 42\n",
      "Converting graphs to vectors...\n",
      "seed: 666\n",
      "Converting graphs to vectors...\n",
      "seed: 888\n",
      "Converting graphs to vectors...\n"
     ]
    }
   ],
   "source": [
    "## Gen data\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for seed in seeds:\n",
    "    train_data, val_data, test_data = load_split_data(seed)\n",
    "    print('seed:', seed)\n",
    "\n",
    "    test_graphs, test_labels, test_paths = load_dataset(test_data, seed)\n",
    "    print(\"Converting graphs to vectors...\")\n",
    "\n",
    "    graph2vec = WLGraph2Vec(num_iterations=3)\n",
    "    # train_vectors = [graph2vec.transform(graph) for graph in train_graphs]\n",
    "    test_vectors = [graph2vec.transform(graph) for graph in test_graphs]\n",
    "    # train_vectors = np.array(train_vectors)\n",
    "    test_vectors = np.array(test_vectors)\n",
    "\n",
    "    dataset[seed] = (test_vectors, test_labels, test_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nn Experiements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 6\n",
      "5-way 5-shot: 0.7682133333333334\n",
      "10-way 5-shot: 0.6999266666666666\n",
      "5-way 10-shot: 0.8368800000000001\n",
      "10-way 10-shot: 0.7638400000000001\n",
      "Seed: 7\n",
      "5-way 5-shot: 0.9198799999999999\n",
      "10-way 5-shot: 0.8832133333333334\n",
      "5-way 10-shot: 0.94086\n",
      "10-way 10-shot: 0.9177099999999999\n",
      "Seed: 10\n",
      "5-way 5-shot: 0.89288\n",
      "10-way 5-shot: 0.84708\n",
      "5-way 10-shot: 0.9121400000000001\n",
      "10-way 10-shot: 0.8795499999999999\n",
      "Seed: 11\n",
      "5-way 5-shot: 0.9643999999999998\n",
      "10-way 5-shot: 0.9495399999999999\n",
      "5-way 10-shot: 0.9784200000000001\n",
      "10-way 10-shot: 0.97028\n",
      "Seed: 19\n",
      "5-way 5-shot: 0.8937466666666667\n",
      "10-way 5-shot: 0.8666533333333334\n",
      "5-way 10-shot: 0.9306000000000001\n",
      "10-way 10-shot: 0.9065899999999999\n",
      "Seed: 22\n",
      "5-way 5-shot: 0.8543466666666666\n",
      "10-way 5-shot: 0.8079400000000001\n",
      "5-way 10-shot: 0.89176\n",
      "10-way 10-shot: 0.8508\n",
      "Seed: 31\n",
      "5-way 5-shot: 0.8920266666666666\n",
      "10-way 5-shot: 0.8348933333333334\n",
      "5-way 10-shot: 0.89654\n",
      "10-way 10-shot: 0.8434100000000001\n",
      "Seed: 42\n",
      "5-way 5-shot: 0.8649466666666666\n",
      "10-way 5-shot: 0.8094\n",
      "5-way 10-shot: 0.90624\n",
      "10-way 10-shot: 0.85704\n",
      "Seed: 666\n",
      "5-way 5-shot: 0.8765466666666666\n",
      "10-way 5-shot: 0.8302866666666666\n",
      "5-way 10-shot: 0.92112\n",
      "10-way 10-shot: 0.88961\n",
      "Seed: 888\n",
      "5-way 5-shot: 0.8609199999999999\n",
      "10-way 5-shot: 0.7556133333333334\n",
      "5-way 10-shot: 0.88634\n",
      "10-way 10-shot: 0.78854\n"
     ]
    }
   ],
   "source": [
    "final_results = {}\n",
    "\n",
    "for seed in seeds:\n",
    "    test_vectors = dataset[seed][0]\n",
    "    test_labels = dataset[seed][1]\n",
    "    test_paths = dataset[seed][2]\n",
    "\n",
    "    print(f\"Seed: {seed}\")\n",
    "    # label encoding\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(test_labels)\n",
    "    test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "    results = evaluate_few_shot(test_vectors, test_labels, n_episodes=1000, mode=\"Nn\")\n",
    "\n",
    "    for config, acc in results.items():\n",
    "        print(f\"{config}: {acc}\")\n",
    "\n",
    "    final_results[seed] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average results:\n",
      "5-way 5-shot: 0.8787906666666666\n",
      "10-way 5-shot: 0.8284546666666668\n",
      "5-way 10-shot: 0.9100900000000001\n",
      "10-way 10-shot: 0.866737\n"
     ]
    }
   ],
   "source": [
    "# calculate average results\n",
    "average_results = defaultdict(float)\n",
    "for seed, results in final_results.items():\n",
    "    for config, acc in results.items():\n",
    "        average_results[config] += acc\n",
    "\n",
    "for config, acc in average_results.items():\n",
    "    average_results[config] = acc / len(seeds)\n",
    "\n",
    "print(\"\\nAverage results:\")\n",
    "for config, acc in average_results.items():\n",
    "    print(f\"{config}: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proto Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-way 5-shot: 0.6821733333333333\n",
      "10-way 5-shot: 0.5899533333333333\n",
      "5-way 10-shot: 0.70338\n",
      "10-way 10-shot: 0.6131899999999999\n",
      "seed: 7\n",
      "5-way 5-shot: 0.8536933333333333\n",
      "10-way 5-shot: 0.8010066666666666\n",
      "5-way 10-shot: 0.8678400000000001\n",
      "10-way 10-shot: 0.80723\n",
      "seed: 10\n",
      "5-way 5-shot: 0.8451733333333333\n",
      "10-way 5-shot: 0.7605999999999999\n",
      "5-way 10-shot: 0.8528000000000001\n",
      "10-way 10-shot: 0.76235\n",
      "seed: 11\n",
      "5-way 5-shot: 0.9332133333333333\n",
      "10-way 5-shot: 0.9115866666666667\n",
      "5-way 10-shot: 0.9308\n",
      "10-way 10-shot: 0.91503\n",
      "seed: 19\n",
      "5-way 5-shot: 0.8322666666666666\n",
      "10-way 5-shot: 0.7784266666666666\n",
      "5-way 10-shot: 0.85102\n",
      "10-way 10-shot: 0.80875\n",
      "seed: 22\n",
      "5-way 5-shot: 0.74608\n",
      "10-way 5-shot: 0.6821333333333334\n",
      "5-way 10-shot: 0.7609799999999999\n",
      "10-way 10-shot: 0.6992299999999999\n",
      "seed: 31\n",
      "5-way 5-shot: 0.8121866666666667\n",
      "10-way 5-shot: 0.7429866666666666\n",
      "5-way 10-shot: 0.8040800000000001\n",
      "10-way 10-shot: 0.7499600000000001\n",
      "seed: 42\n",
      "5-way 5-shot: 0.8226133333333333\n",
      "10-way 5-shot: 0.7193066666666666\n",
      "5-way 10-shot: 0.8249000000000001\n",
      "10-way 10-shot: 0.73345\n",
      "seed: 666\n",
      "5-way 5-shot: 0.7757733333333333\n",
      "10-way 5-shot: 0.6954866666666667\n",
      "5-way 10-shot: 0.7741\n",
      "10-way 10-shot: 0.7031799999999999\n",
      "seed: 888\n",
      "5-way 5-shot: 0.79204\n",
      "10-way 5-shot: 0.6464666666666667\n",
      "5-way 10-shot: 0.8046\n",
      "10-way 10-shot: 0.66342\n"
     ]
    }
   ],
   "source": [
    "## Proto mode\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    test_vectors = dataset[seed][0]\n",
    "    test_labels = dataset[seed][1]\n",
    "    test_paths = dataset[seed][2]\n",
    "    print('seed:', seed)\n",
    "    # label encoding\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(test_labels)\n",
    "    test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "    results = evaluate_few_shot(test_vectors, test_labels, n_episodes=1000, mode=\"Proto\")\n",
    "\n",
    "    for config, result in results.items():\n",
    "        print(f\"{config}: {result[0]}\")\n",
    "        # if config == \"10-way 5-shot\":\n",
    "        #     print(result[1])\n",
    "\n",
    "\n",
    "    final_results[seed] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average results:\n",
      "5-way 5-shot: 0.8095213333333332\n",
      "10-way 5-shot: 0.7327953333333334\n",
      "5-way 10-shot: 0.81745\n",
      "10-way 10-shot: 0.745579\n"
     ]
    }
   ],
   "source": [
    "# calculate average results\n",
    "average_results = defaultdict(float)\n",
    "for seed, results in final_results.items():\n",
    "    for config, result in results.items():\n",
    "        average_results[config] += result[0]\n",
    "\n",
    "for config, acc in average_results.items():\n",
    "    average_results[config] = acc / len(seeds)\n",
    "\n",
    "print(\"\\nAverage results:\")\n",
    "for config, acc in average_results.items():\n",
    "    print(f\"{config}: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def visualize_tsne(test_vectors, test_labels, seed, mode):\n",
    "    \"\"\"\n",
    "    使用t-SNE將高維向量視覺化\n",
    "    \n",
    "    參數:\n",
    "        test_vectors: numpy array of shape (n_samples, n_features)\n",
    "        test_labels: numpy array of shape (n_samples,)\n",
    "        seed: 當前的隨機種子\n",
    "    \"\"\"\n",
    "    # 確保數據是numpy數組\n",
    "    test_vectors = np.array(test_vectors)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    # 標準化數據\n",
    "    scaler = StandardScaler()\n",
    "    test_vectors_scaled = scaler.fit_transform(test_vectors)\n",
    "    \n",
    "    # 應用t-SNE\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=30,\n",
    "        random_state=42,\n",
    "        init='pca',  # 使用PCA初始化\n",
    "        learning_rate='auto'  # 自動選擇學習率\n",
    "    )\n",
    "    \n",
    "    # 轉換數據\n",
    "    test_vectors_tsne = tsne.fit_transform(test_vectors_scaled)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # 使用不同的配色方案\n",
    "    n_classes = len(np.unique(test_labels))\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, n_classes))\n",
    "    \n",
    "\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    # 繪製散點圖\n",
    "    for i, label in enumerate(np.unique(test_labels)):\n",
    "        mask = test_labels == label\n",
    "        plt.scatter(\n",
    "            test_vectors_tsne[mask, 0],\n",
    "            test_vectors_tsne[mask, 1],\n",
    "            c='None',\n",
    "            edgecolors=[colors[i]],\n",
    "            label=f'Family {label}',\n",
    "            alpha=1.0,\n",
    "            s=100,\n",
    "            linewidth=1.5\n",
    "        )\n",
    "    \n",
    "    # 添加標題和標籤\n",
    "    plt.title(f\"t-SNE Visualization (Seed {seed})\", fontsize=14, pad=20)\n",
    "    plt.xlabel(\"t-SNE Component 1\", fontsize=12)\n",
    "    plt.ylabel(\"t-SNE Component 2\", fontsize=12)\n",
    "    \n",
    "    # 調整圖例\n",
    "    plt.legend(\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc='upper left',\n",
    "        borderaxespad=0.,\n",
    "        title=\"Malware Families\",\n",
    "        title_fontsize=12,\n",
    "        fontsize=10\n",
    "    )\n",
    "    \n",
    "    # 調整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # # 顯示圖形\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"./tsne_pic/tsne_{mode}_seed_{seed}.png\")\n",
    "    # 關閉圖形以釋放內存\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grah2vec data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 6\n",
      "Seed: 7\n",
      "Seed: 10\n",
      "Seed: 11\n",
      "Seed: 19\n",
      "Seed: 22\n",
      "Seed: 31\n",
      "Seed: 42\n",
      "Seed: 666\n",
      "Seed: 888\n"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "for seed in seeds:\n",
    "\n",
    "    print('Seed:', seed)\n",
    "    \n",
    "    test_vectors = dataset[seed][0]\n",
    "    test_labels = dataset[seed][1]\n",
    "    test_paths = dataset[seed][2]\n",
    "    \n",
    "    # 檢查並處理NaN值\n",
    "    if np.isnan(test_vectors).any():\n",
    "        print(\"Warning: Found NaN values in vectors, replacing with 0\")\n",
    "        test_vectors = np.nan_to_num(test_vectors, nan=0.0)\n",
    "    \n",
    "    # 視覺化\n",
    "    visualize_tsne(test_vectors, test_labels, seed, mode=\"graph2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot random graphSAGE distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from models import GraphSAGE, GCN\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "for seed in seeds:\n",
    "    path = f\"/home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_{seed}/word2vec/testData.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        data_list = data[0]\n",
    "        label = data[1]\n",
    "    print(f\"Seed: {seed}\")\n",
    "\n",
    "    model = GraphSAGE(dim_in=128, dim_h=128, dim_out=128, num_layers=2, projection = True)\n",
    "\n",
    "\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    output = model(batch)\n",
    "    visualize_tsne(output.detach().numpy(), label, seed, mode=\"GraphSAGE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "from loadDataset import LoadDataset\n",
    "from trainModule import TestModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 6, Experiment: 5way_5shot_NnNet_with_pretrain_20250104_010925\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_5shot_NnNet_with_pretrain_20250104_010925/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8124\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:20<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.11it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8562\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_10shot_NnNet_with_pretrain_20250104_113856\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_10shot_NnNet_with_pretrain_20250104_113856/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8383\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:25<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.25it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.9041\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_10shot_NnNet_without_pretrain_20250106_171935\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_10shot_NnNet_without_pretrain_20250106_171935/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.7875\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.27it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8907\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_10shot_NnNet_with_pretrain_20250106_153519\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_10shot_NnNet_with_pretrain_20250106_153519/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.7936\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8804\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_5shot_ProtoNet_with_pretrain_20250103_174933\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_5shot_ProtoNet_with_pretrain_20250103_174933/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6591\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.38it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6358\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_10shot_ProtoNet_with_pretrain_20250104_030057\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_10shot_ProtoNet_with_pretrain_20250104_030057/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6673\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:26<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:25<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:21<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.47it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6004\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_5shot_NnNet_without_pretrain_20250105_143425\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_5shot_NnNet_without_pretrain_20250105_143425/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.7432\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8079\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_5shot_NnNet_with_pretrain_20250105_115117\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_5shot_NnNet_with_pretrain_20250105_115117/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.7546\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:40<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:38<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:39<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.27it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8213\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_10shot_NnNet_without_pretrain_20250104_121300\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_10shot_NnNet_without_pretrain_20250104_121300/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8313\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:21<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:19<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.22it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.9050\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_5shot_ProtoNet_with_pretrain_20250104_124204\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_5shot_ProtoNet_with_pretrain_20250104_124204/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5406\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:40<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:39<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5492\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_10shot_ProtoNet_without_pretrain_20250106_035248\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_10shot_ProtoNet_without_pretrain_20250106_035248/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:29<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5923\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:42<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:42<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5152\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_5shot_ProtoNet_without_pretrain_20250104_003419\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_5shot_ProtoNet_without_pretrain_20250104_003419/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6667\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:20<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.14it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6303\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_10shot_ProtoNet_with_pretrain_20250105_152327\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_10shot_ProtoNet_with_pretrain_20250105_152327/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manying/Projects/fcgFewShot/trainModule.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f\"Ablation evaluation... (testing dataset)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5516\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:39<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:39<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:38<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:40<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5169\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_10shot_ProtoNet_without_pretrain_20250104_053453\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_10shot_ProtoNet_without_pretrain_20250104_053453/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6949\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:20<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:19<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:21<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.17it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.6298\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 10way_5shot_ProtoNet_without_pretrain_20250105_001310\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/10way_5shot_ProtoNet_without_pretrain_20250105_001310/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5588\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:39<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n",
      "/home/manying/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.5352\n",
      "Finish evaluation\n",
      "\n",
      "\n",
      "Seed: 6, Experiment: 5way_5shot_NnNet_without_pretrain_20250104_014312\n",
      "Config: /home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_6/5way_5shot_NnNet_without_pretrain_20250104_014312/config.json\n",
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Setting up the testing module...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /home/manying/Projects/fcgFewShot/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Ablation evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:16<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:15<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.7907\n",
      "Ablation evaluation... (validation dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:24<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:22<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:23<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8438\n",
      "Finish evaluation\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for seed in seeds:\n",
    "    dataset_folder = f\"/home/manying/Projects/fcgFewShot/checkpoints/x86_64_withVal_withPretrain_ghidra_{seed}\"\n",
    "    for exp in os.listdir(dataset_folder):\n",
    "        if os.path.isdir(os.path.join(dataset_folder, exp)):\n",
    "            config = load_config(os.path.join(dataset_folder, exp, 'config.json'))\n",
    "            config_path = os.path.join(dataset_folder, exp, 'config.json')\n",
    "            config[\"paths\"][\"data\"][\"embedding_folder\"] = \"/home/manying/Projects/fcgFewShot/embeddings\"\n",
    "            print(f\"Seed: {seed}, Experiment: {exp}\")\n",
    "            print(f\"Config: {config_path}\")\n",
    "            dataset = LoadDataset(config)\n",
    "            test_module = TestModule(config_path, dataset, config)\n",
    "            test_module.temp_eval()\n",
    "            print(\"\\n\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
