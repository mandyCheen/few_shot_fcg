{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config, save_config\n",
    "options = load_config(\"./config/config_label_prop.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Word2vec model exist, load word2vec model...\n",
      "Start to get node embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580/1580 [00:00<00:00, 47255.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish getting node embedding\n",
      "Setting up the training module...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading training data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/trainData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Device: cuda:0\n",
      "Model: LabelPropagation(\n",
      "  (relation): GraphRelationNetwork(\n",
      "    (sage): GraphSAGELayer(\n",
      "      (sage_convs): ModuleList(\n",
      "        (0-1): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): GraphSAGELayer(\n",
      "    (sage_convs): ModuleList(\n",
      "      (0): SAGEConv(128, 64, aggr=mean)\n",
      "      (1-2): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (norms): ModuleList(\n",
      "      (0-2): 3 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Loss function: LabelPropagation(\n",
      "  (relation): GraphRelationNetwork(\n",
      "    (sage): GraphSAGELayer(\n",
      "      (sage_convs): ModuleList(\n",
      "        (0-1): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): GraphSAGELayer(\n",
      "    (sage_convs): ModuleList(\n",
      "      (0): SAGEConv(128, 64, aggr=mean)\n",
      "      (1-2): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (norms): ModuleList(\n",
      "      (0-2): 3 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Finish setting up the training module\n",
      "Copying split files...\n",
      "Finish copying split files\n",
      "Start training...\n",
      "Current learning rate: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 (Training): 100%|██████████| 100/100 [00:14<00:00,  6.88it/s, loss=0.9276, acc=0.4800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.6597, Avg Train Acc: 0.5876 (Best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 (Validation):  17%|█▋        | 17/100 [00:02<00:08, 10.31it/s, loss=0.4833, acc=0.7733]"
     ]
    }
   ],
   "source": [
    "from loadDataset import LoadDataset\n",
    "from fcgVectorize import FCGVectorize\n",
    "from trainModule import TrainModule\n",
    "from trainModule import TestModule\n",
    "import os\n",
    "\n",
    "dataset = LoadDataset(options, pretrain=False)\n",
    "vectorizer = FCGVectorize(options, dataset)\n",
    "vectorizer.node_embedding(dataset.rawDataset)\n",
    "trainModule = TrainModule(options, dataset)\n",
    "trainModule.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy/Projects/few_shot_fcg/trainModule.py:337: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_path, map_location=self.device)[\"model_state_dict\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the testing module...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading validation data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Loading testing data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Loading model from ./checkpoints/x86_64_withVal_withPretrain_ghidra_6_baseline/5way_5shot_LabelPropagation_20250225_103122/epoch_17_best.pth\n",
      "Best model loaded\n",
      "Model: LabelPropagation(\n",
      "  (relation): GraphRelationNetwork(\n",
      "    (sage): GraphSAGELayer(\n",
      "      (sage_convs): ModuleList(\n",
      "        (0-1): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): GraphSAGELayer(\n",
      "    (sage_convs): ModuleList(\n",
      "      (0): SAGEConv(128, 64, aggr=mean)\n",
      "      (1-3): 3 x SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (norms): ModuleList(\n",
      "      (0-3): 4 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start evaluation... (testing dataset)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:05<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:05<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:06<00:00, 14.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.7334\n",
      "Finish evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test = TestModule(os.path.join(trainModule.model_folder, \"config.json\"), dataset, options)\n",
    "test.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
