{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "from loadDataset import LoadDataset\n",
    "from trainModule import TrainModule, TestModule\n",
    "from fcgVectorize import FCGVectorize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"dataset\": {\n",
    "        \"pack_filter\": \"diec\",\n",
    "        \"cpu_arch\": \"x86_64\",\n",
    "        \"reverse_tool\": \"ghidra\",\n",
    "        \"raw\": \"malware_diec_ghidra_x86_64_fcg_dataset.csv\",\n",
    "        \"split_by_cpu\": False,\n",
    "        \"pretrain_family\": [\n",
    "            \"gafgyt\",\n",
    "            \"ngioweb\",\n",
    "            \"mirai\",\n",
    "            \"tsunami\"\n",
    "        ]\n",
    "    },\n",
    "    \"pretrain\": {\n",
    "        \"name\": \"x86_pretrained\",\n",
    "        \"use\": True,\n",
    "        \"raw_dataset\": \"malware_diec_ghidra_x86_64_fcg_pretrain_dataset.csv\",\n",
    "        \"batch_size\": 128\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"name\": \"10way_5shot_ProtoNet_with_pretrain\",\n",
    "        \"model\": {\n",
    "            \"model_name\": \"GraphSAGE\",\n",
    "            \"input_size\": 128,\n",
    "            \"hidden_size\": 128,\n",
    "            \"output_size\": 128,\n",
    "            \"num_layers\": 2,\n",
    "            \"projection\": True,\n",
    "            \"load_weights\": \"x86_pretrained_20241121_1653\"\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"training\": True,\n",
    "            \"validation\": True,\n",
    "            \"num_epochs\": 500,\n",
    "            \"device\": \"cuda:0\",\n",
    "            \"parallel\": False,\n",
    "            \"parallel_device\": [],\n",
    "            \"iterations\": 100,\n",
    "            \"lr\": 0.0005,\n",
    "            \"projection_lr\": 0.001,\n",
    "            \"lr_scheduler\": {\n",
    "                \"use\": True,\n",
    "                \"method\": \"ReduceLROnPlateau\",\n",
    "                \"step_size\": 20,\n",
    "                \"gamma\": 0.5,\n",
    "                \"patience\": 10,\n",
    "                \"factor\": 0.5\n",
    "            },\n",
    "            \"early_stopping\": {\n",
    "                \"use\": True,\n",
    "                \"patience\":  30\n",
    "            },\n",
    "            \"loss\": \"CrossEntropyLoss\",\n",
    "            \"distance\": \"euclidean\",\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"save_model\": True,\n",
    "        },\n",
    "        \"few_shot\": {\n",
    "            \"method\": \"ProtoNet\",\n",
    "            \"train\": {\n",
    "                \"support_shots\": 5,\n",
    "                \"query_shots\": 15,\n",
    "                \"class_per_iter\": 10\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"support_shots\": 5,\n",
    "                \"query_shots\": 15,\n",
    "                \"class_per_iter\": 10\n",
    "            }\n",
    "        },\n",
    "        \"vectorize\": {\n",
    "            \"node_embedding_method\": \"word2vec\",\n",
    "            \"node_embedding_size\": 128,\n",
    "            \"num_workers\": 4\n",
    "        },\n",
    "        \"seed\": 7\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"data\": {\n",
    "            \"fcg_dataset\": \"./dataset/data_ghidra_fcg\",\n",
    "            \"csv_folder\": \"./dataset/raw_csv\",\n",
    "            \"split_folder\": \"./dataset/split\",\n",
    "            \"embedding_folder\": \"/mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/\",\n",
    "            \"pretrain_dataset\": \"./dataset/data_ghidra_fcg_pretrain\"\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"model_folder\": \"./checkpoints\",\n",
    "            \"pretrained_folder\": \"./pretrained\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Word2vec model exist, load word2vec model...\n",
      "Start to get node embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580/1580 [00:00<00:00, 20311.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish getting node embedding\n",
      "Setting up the training module...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_7/word2vec...\n",
      "Loading training data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_7/word2vec/trainData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_7/word2vec/valData.pkl...\n",
      "Model loaded from ./pretrained/x86_pretrained_20241121_1653/epoch_2060_best_backbone.pth\n",
      "Device: cuda:0\n",
      "Model: GraphSAGE(\n",
      "  (sage_convs): ModuleList(\n",
      "    (0-1): 2 x SAGEConv(128, 128, aggr=mean)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-1): 2 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (output_proj): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n",
      "Loss function: <loss.ProtoLoss object at 0x738fdf173f50>\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Finish setting up the training module\n"
     ]
    }
   ],
   "source": [
    "dataset = LoadDataset(options)                                   \n",
    "vectorize = FCGVectorize(options, dataset)                  \n",
    "vectorize.node_embedding(dataset.rawDataset)                                                    \n",
    "train = TrainModule(options, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.int64\n",
      "Data(x=[13, 128], edge_index=[2, 0], label=[13], name='code', y=9)\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for i, data in enumerate(train.valGraph):\n",
    "    for node in data.x:\n",
    "        typeOfNode = node.dtype\n",
    "        if typeOfNode != torch.float32:\n",
    "            print(node)\n",
    "            print(typeOfNode)\n",
    "            print(data)\n",
    "            print(i)\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# for i,data in enumerate(train.valLoader):\n",
    "#     data = data.to(train.device)\n",
    "#     with torch.no_grad():\n",
    "#         model_output = train.model(data)\n",
    "#         loss, acc = train.loss_fn(model_output, data.y)\n",
    "#     print(data.y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
