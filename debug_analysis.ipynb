{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check embedding error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra/word2vec/Advanced Micro Devices X86-64/aidra/81193e9a87778d7899a523adc7949f1a8af267d268e1dd51298165c22b890f4e.gpickle\"\n",
    "\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "    \n",
    "node = \"0x4012f0L\"\n",
    "\n",
    "print(G.nodes[node])\n",
    "G.nodes[node][\"x\"] = []\n",
    "print(G.nodes[node])\n",
    "\n",
    "# with open(path, \"wb\") as f:\n",
    "#     pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def check_model_weights(model_path, device):\n",
    "    # 載入模型\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    # 1. 檢查state dict是否為空\n",
    "    if not checkpoint[\"model_state_dict\"]:\n",
    "        print(\"Warning: Model state dict is empty!\")\n",
    "        return False\n",
    "        \n",
    "    # 2. 印出模型的所有權重名稱和形狀\n",
    "    for name, param in checkpoint[\"model_state_dict\"].items():\n",
    "        print(f\"Layer: {name} | Shape: {param.shape}\")\n",
    "        print(param)\n",
    "        \n",
    "    # 3. 檢查權重是否包含非零值\n",
    "    for param in checkpoint[\"model_state_dict\"].values():\n",
    "        if torch.all(param == 0):\n",
    "            print(f\"Warning: Found all-zero parameter tensor!\")\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"pretrained/x86_pretrained_20241122_1616/epoch_1342_best_backbone.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "check_model_weights(path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check validation dataset & test dataset difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "testPath = \"/mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra/word2vec/testData.pkl\"\n",
    "valPath = \"/mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra/word2vec/valData.pkl\"\n",
    "\n",
    "with open(testPath, \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "with open(valPath, \"rb\") as f:\n",
    "    val = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test[0]))\n",
    "print(len(val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAvgLen = sum([len(graph.x) for graph in test[0]]) / len(test[0])\n",
    "valAvgLen = sum([len(graph.x) for graph in val[0]]) / len(val[0])\n",
    "\n",
    "print(testAvgLen)\n",
    "print(valAvgLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get label dictionary data when loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "from loadDataset import LoadDataset\n",
    "from trainModule import TestModule\n",
    "import os\n",
    "\n",
    "seeds = [6, 7, 10, 11, 19, 22, 31, 42, 666, 888]\n",
    "\n",
    "for seed in seeds:\n",
    "    configPath = f\"/home/manying/Projects/fcgFewShot/config/config_NICT_Ghidra_x86_64_{seed}.json\"\n",
    "    options = load_config(configPath)\n",
    "    \n",
    "    options[\"paths\"][\"data\"][\"embedding_folder\"] = \"/home/manying/Projects/fcgFewShot/embeddings\"\n",
    "    dataset = LoadDataset(options)\n",
    "    test = TestModule(configPath, dataset, options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: train on 10-way test on 5-way performance\n",
    "Testing on seed_6_baseline: LP 10-way 5-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config, save_config\n",
    "import os\n",
    "from loadDataset import LoadDataset\n",
    "from trainModule import TestModule\n",
    "configPath = \"/home/mandy/Projects/few_shot_fcg/checkpoints/x86_64_withVal_withPretrain_ghidra_6_baseline/10way_5shot_LabelPropagation_alpha0.7_k20_20250315_155140/config.json\"\n",
    "options = load_config(configPath)\n",
    "newConfigPath = os.path.join(os.path.dirname(configPath), \"config_5way.json\")\n",
    "### change settings\n",
    "options[\"settings\"][\"few_shot\"][\"test\"][\"class_per_iter\"] = 5\n",
    "options[\"settings\"][\"train\"][\"distance\"] = \"euclidean\"\n",
    "save_config(options, newConfigPath)\n",
    "\n",
    "dataset = LoadDataset(options)\n",
    "\n",
    "test = TestModule(newConfigPath, dataset)\n",
    "test.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis diff backbone parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GraphSAGELayer, GATLayer, GCNLayer, GINLayer\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "dims = dict(dim_in=128, dim_h=128, dim_o=128, num_layers=3)\n",
    "models = {\n",
    "    'GCN'      : GCNLayer(**dims),\n",
    "    'GraphSAGE': GraphSAGELayer(**dims),\n",
    "    'GAT'      : GATLayer(**dims, heads=8),\n",
    "    'GIN'      : GINLayer(**dims)\n",
    "}\n",
    "\n",
    "for name, m in models.items():\n",
    "    print(f'{name}: {count_params(m):,} parameters')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check fcg node without \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_path = \"/home/manying/Projects/fcgFewShot/dataset/data_ghidra_fcg_openset/Intel 80386\"\n",
    "\n",
    "import os, pickle\n",
    "\n",
    "for familyFolder in os.listdir(check_path):\n",
    "    familyPath = os.path.join(check_path, familyFolder)\n",
    "    if not os.path.isdir(familyPath):\n",
    "        continue\n",
    "    for file in os.listdir(familyPath):\n",
    "        filePath = os.path.join(familyPath, file)\n",
    "        if not file.endswith(\".gpickle\"):\n",
    "            continue\n",
    "        with open(filePath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            for node in data.nodes:\n",
    "                if \"x\" not in data.nodes[node]:\n",
    "                    print(f\"Node {node} in file {filePath} does not have 'x' attribute.\")\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./dataset/data_ghidra_fcg/Intel 80386/ddostf/000f5bc23812367aecf93ff5d6c96ac644f0ae819096af6eab13eb1993b8dbe4.gpickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check ARM malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "familyList = [\"tediss\", \"dowgin\", \"mobidash\", \"helper\", \"sagent\", \"zergrush\", \"zhtrap\", \"rootnik\", \"boqx\", \"mirai\", \"gafgyt\", \"shixot\", \"feejar\", \"gluper\", \"dofloo\", \"dnsamp\", \"sidewalk\", \"wapron\", \"badpac\", \"ngioweb\", \"tekya\", \"monitorminor\", \"meterpreter\"]\n",
    "dataPath = \"/home/manying/Projects/fcgFewShot/dataset/data_ghidra_fcg/ARM\"\n",
    "embedPath = \"/home/manying/Projects/fcgFewShot/embeddings/arm_withVal_ghidra_42/word2vec/ARM\"\n",
    "\n",
    "for familyFolder in familyList:\n",
    "    familyPath = os.path.join(dataPath, familyFolder)\n",
    "    embedFamilyPath = os.path.join(embedPath, familyFolder)\n",
    "    if not os.path.isdir(familyPath):\n",
    "        print(f\"Family folder {familyFolder} does not exist in {dataPath}.\")\n",
    "        continue\n",
    "    for file in os.listdir(familyPath):\n",
    "        filePath = os.path.join(familyPath, file)\n",
    "        print(filePath)\n",
    "        if not file.endswith(\".gpickle\"):\n",
    "            continue\n",
    "        with open(filePath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            print(data)\n",
    "            for node in data.nodes:\n",
    "                print(data.nodes[node])\n",
    "    for file in os.listdir(embedFamilyPath):\n",
    "        filePath = os.path.join(embedFamilyPath, file)\n",
    "        if not file.endswith(\".gpickle\"):\n",
    "            continue\n",
    "        with open(filePath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            print(data)\n",
    "            for node in data.nodes:\n",
    "                print(data.nodes[node])\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test maml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (1180, 16)\n",
      "train dataset family number: 59\n",
      "test dataset shape: (200, 16)\n",
      "test dataset family number: 10\n",
      "val dataset shape: (200, 16)\n",
      "val dataset family number: 10\n",
      "Loading openset data...\n",
      "Openset data shape: (342, 16)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_config\n",
    "from loadDataset import LoadDataset\n",
    "from trainModule import TestModule, TrainModule\n",
    "from fcgVectorize import FCGVectorize\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "path = \"./config/config_maml_gcn.json\"\n",
    "\n",
    "options = load_config(path)\n",
    "\n",
    "dataset = LoadDataset(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the training module...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Loading training data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/trainData.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/valData.pkl...\n",
      "Device: cuda:0\n",
      "Model: MAMLLoss(\n",
      "  (encoder): GraphClassifier(\n",
      "    (backbone): GCN(\n",
      "      (gcn_convs): ModuleList(\n",
      "        (0-2): 3 x GCNConv(128, 128)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Loss function: MAMLLoss(\n",
      "  (encoder): GraphClassifier(\n",
      "    (backbone): GCN(\n",
      "      (gcn_convs): ModuleList(\n",
      "        (0-2): 3 x GCNConv(128, 128)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Finish setting up the training module\n",
      "Copying split files...\n",
      "Finish copying split files\n",
      "Start training...\n",
      "Current learning rate: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 (Training): 100%|██████████| 100/100 [00:31<00:00,  3.18it/s, loss=1.3864, acc=0.4200, openset_auc=N/A]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0310, Avg Train Acc: 0.6364 (Best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 (Validation): 100%|██████████| 100/100 [00:23<00:00,  4.27it/s, loss=1.5633, acc=0.2400, openset_auc=N/A]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.3968, Avg Val Acc: 0.4266 (Best)\n",
      "Current learning rate: [0.001]\n",
      "Patience: 0/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 (Training):  28%|██▊       | 28/100 [00:08<00:16,  4.49it/s, loss=0.9900, acc=0.6000, openset_auc=N/A]"
     ]
    }
   ],
   "source": [
    "trainModule = TrainModule(options, dataset)\n",
    "trainModule.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the testing module...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/testData.pkl...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec...\n",
      "Generating open set testing data...\n",
      "Loading openset data...\n",
      "Loading data from /mnt/ssd2t/mandy/Projects/few_shot_fcg/embeddings/x86_64_withVal_withPretrain_ghidra_6/word2vec/opensetData_random_0.2.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy/Tools/anaconda3/envs/prototype/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish setting up the testing module\n",
      "Model path is not provided. Using the best model...\n",
      "Record evaluation log...\n",
      "Loading model from /home/mandy/Projects/few_shot_fcg/checkpoints/x86_64_withVal_withPretrain_ghidra_6_others/5way_10shot_MAML_gcn_20250704_225322/epoch_1_0.19999998807907104_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy/Projects/few_shot_fcg/trainModule.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_path, map_location=self.device)[\"model_state_dict\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MAMLLoss(\n",
      "  (encoder): GraphClassifier(\n",
      "    (backbone): GCN(\n",
      "      (gcn_convs): ModuleList(\n",
      "        (0-2): 3 x GCNConv(128, 128)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start evaluation... (testing dataset)\n",
      "Open set evaluation enabled\n",
      "Open set m_samples: 50\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   1%|          | 1/100 [00:00<00:50,  1.96it/s, loss=1.2544, acc=0.4000, openset_auc=0.4200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   2%|▏         | 2/100 [00:00<00:37,  2.60it/s, loss=1.5316, acc=0.3800, openset_auc=0.4444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 0, 3, 1,\n",
      "        3, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   3%|▎         | 3/100 [00:01<00:33,  2.91it/s, loss=1.3705, acc=0.4600, openset_auc=0.4552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 1, 4, 1, 1, 1, 0, 3, 4, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 4, 3, 1, 1,\n",
      "        3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   4%|▍         | 4/100 [00:01<00:29,  3.23it/s, loss=1.5817, acc=0.1800, openset_auc=0.2816]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   5%|▌         | 5/100 [00:01<00:28,  3.37it/s, loss=1.1893, acc=0.7000, openset_auc=0.2972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2, 3, 2, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   6%|▌         | 6/100 [00:01<00:30,  3.12it/s, loss=1.2505, acc=0.5600, openset_auc=0.3952]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2,\n",
      "        2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   7%|▋         | 7/100 [00:02<00:28,  3.26it/s, loss=1.3810, acc=0.6200, openset_auc=0.2336]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 2, 2,\n",
      "        3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   8%|▊         | 8/100 [00:02<00:29,  3.14it/s, loss=1.3983, acc=0.2000, openset_auc=0.1936]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):   9%|▉         | 9/100 [00:02<00:27,  3.26it/s, loss=1.8882, acc=0.3800, openset_auc=0.2648]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 3, 3, 0, 0, 0, 3, 1, 0, 0, 1, 1, 3, 1, 3, 3, 1, 1, 1, 1, 1, 3, 2, 3,\n",
      "        2, 0, 2, 2, 2, 1, 3, 1, 1, 2, 2, 2, 1, 1, 2, 1, 3, 3, 2, 3, 3, 3, 3, 3,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  10%|█         | 10/100 [00:03<00:27,  3.25it/s, loss=1.7397, acc=0.1600, openset_auc=0.3192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 1, 1, 3, 1, 3, 1, 3, 3,\n",
      "        3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  11%|█         | 11/100 [00:03<00:24,  3.63it/s, loss=1.1988, acc=0.7000, openset_auc=0.3468]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0,\n",
      "        2, 2, 2, 0, 2, 0, 2, 3, 3, 0, 3, 0, 2, 0, 3, 3, 4, 4, 2, 4, 3, 4, 3, 2,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  12%|█▏        | 12/100 [00:03<00:22,  3.86it/s, loss=1.2453, acc=0.4000, openset_auc=0.5428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  13%|█▎        | 13/100 [00:03<00:22,  3.84it/s, loss=1.2183, acc=0.4400, openset_auc=0.4444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  14%|█▍        | 14/100 [00:04<00:23,  3.58it/s, loss=1.2975, acc=0.5800, openset_auc=0.4608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 1, 3, 1, 3,\n",
      "        3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  15%|█▌        | 15/100 [00:04<00:23,  3.59it/s, loss=1.3341, acc=0.6000, openset_auc=0.4996]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 0, 1, 2, 2, 3, 3,\n",
      "        2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  16%|█▌        | 16/100 [00:04<00:21,  3.85it/s, loss=1.3928, acc=0.4600, openset_auc=0.3720]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 4,\n",
      "        1, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  17%|█▋        | 17/100 [00:04<00:21,  3.79it/s, loss=1.4104, acc=0.2200, openset_auc=0.2888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 3, 3, 3, 2, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        3, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  18%|█▊        | 18/100 [00:05<00:20,  3.92it/s, loss=1.5495, acc=0.2400, openset_auc=0.3624]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 3, 1, 1, 1, 3,\n",
      "        1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  19%|█▉        | 19/100 [00:05<00:19,  4.05it/s, loss=1.6687, acc=0.5000, openset_auc=0.3028]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0,\n",
      "        2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0,\n",
      "        0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  20%|██        | 20/100 [00:05<00:20,  3.84it/s, loss=1.3577, acc=0.4200, openset_auc=0.3148]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 3, 4, 3, 3, 3, 3, 3, 0, 1, 0, 3,\n",
      "        0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  21%|██        | 21/100 [00:06<00:21,  3.65it/s, loss=1.2652, acc=0.7600, openset_auc=0.3768]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 3, 3, 2, 3,\n",
      "        2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  22%|██▏       | 22/100 [00:06<00:23,  3.34it/s, loss=1.2614, acc=0.6000, openset_auc=0.5676]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 3, 3, 1,\n",
      "        1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  23%|██▎       | 23/100 [00:06<00:21,  3.58it/s, loss=1.5312, acc=0.2400, openset_auc=0.2856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
      "        3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  24%|██▍       | 24/100 [00:06<00:19,  3.87it/s, loss=2.0639, acc=0.3400, openset_auc=0.2460]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 1, 1, 3, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  25%|██▌       | 25/100 [00:07<00:18,  4.11it/s, loss=1.5034, acc=0.2200, openset_auc=0.3692]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 0, 3, 3, 3, 3,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  26%|██▌       | 26/100 [00:07<00:19,  3.88it/s, loss=1.3328, acc=0.4000, openset_auc=0.3988]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3,\n",
      "        1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  27%|██▋       | 27/100 [00:07<00:18,  3.96it/s, loss=1.3209, acc=0.6000, openset_auc=0.4836]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 0, 3, 3, 1,\n",
      "        1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  28%|██▊       | 28/100 [00:07<00:17,  4.04it/s, loss=1.5069, acc=0.2800, openset_auc=0.2468]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3,\n",
      "        2, 2], device='cuda:0')\n",
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  29%|██▉       | 29/100 [00:08<00:16,  4.36it/s, loss=1.5338, acc=0.3800, openset_auc=0.2120]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 3, 3, 3, 3, 1, 3, 3, 3,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  30%|███       | 30/100 [00:08<00:16,  4.30it/s, loss=1.4734, acc=0.2400, openset_auc=0.2384]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3,\n",
      "        3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  31%|███       | 31/100 [00:08<00:15,  4.37it/s, loss=1.2680, acc=0.5800, openset_auc=0.3436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  32%|███▏      | 32/100 [00:08<00:15,  4.31it/s, loss=1.1567, acc=0.7400, openset_auc=0.3072]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  33%|███▎      | 33/100 [00:08<00:15,  4.28it/s, loss=1.5353, acc=0.2200, openset_auc=0.4652]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n",
      "        2, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  34%|███▍      | 34/100 [00:09<00:16,  3.90it/s, loss=1.0898, acc=0.6000, openset_auc=0.3232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 0, 2, 2, 0,\n",
      "        0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Testing):  35%|███▌      | 35/100 [00:09<00:16,  3.95it/s, loss=1.2890, acc=0.6000, openset_auc=0.3808]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 1, 0, 3, 0,\n",
      "        0, 0], device='cuda:0')\n",
      "targets: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3,\n",
      "        1, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test = TestModule(\"/home/mandy/Projects/few_shot_fcg/checkpoints/x86_64_withVal_withPretrain_ghidra_6_others/5way_10shot_MAML_gcn_20250704_225322/config.json\", dataset)\n",
    "test.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
